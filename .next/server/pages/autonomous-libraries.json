{"pageProps":{"project":{"html":"<p>Autonomous Libraries (AL) was an R&amp;D project where we asked: what would a library look like if we designed it from scratch for the age of digital knowledge production? Instead of one big central building, AL imagined a distributed network of hybrid knowledge spaces — modular, self-managed, community-run, and spread across everyday environments like coffeehouses, squares, or train stations.</p>\n<p>We combined all the core technologies we had developed at Suslib — Knowledge Recognition for semantic search and contextual linking, Intention Recognition for gesture- and object-based interaction, and lightweight AR interfaces to connect digital and physical resources. The result was a new kind of space: one where you could pick up a book and instantly see its digital context, annotate a page with thoughts and images, or continue reading seamlessly on your device after leaving.</p>\n<p>As a team, we treated AL as both a design research exercise and a technological prototype. I led the engineering direction, ensuring our APIs and ML systems could integrate into a hybrid physical-digital environment, while collaborating closely with Martijn on interaction design and Studio Helioripple on modular architectural systems.</p>\n<p>AL was never meant to be a single app or product, but a vision of community-driven, resilient, non-commercial knowledge infrastructure — one that could exist anywhere in the city, belong to everyone, and evolve with new forms of knowledge production.</p>\n<p><code>with</code> <a href=\"https://suslib.com\">Martijn de Heer</a> (co-founder, designer), <a href=\"https://suslib.com\">Studio Helioripple</a> (Amin Bahrami)</p>\n","link":"https://suslib.com/research/autonomous-libraries","title":"Autonomous Libraries","description":"<p>We combined all the core technologies we had developed at Suslib — Knowledge Recognition for semantic search and contextual linking, Intention Recognition for gesture- and object-based interaction, and lightweight AR interfaces to connect digital and physical resources. The result was a new kind of space: one where you could pick up a book and instantly see its digital context, annotate a page with thoughts and images, or continue reading seamlessly on your device after leaving.</p>\n","blurb":"R&D project reimagining libraries as distributed networks of hybrid knowledge spaces with AI-powered semantic search and AR interfaces.","tags":["R&D","future-of-knowledge","smart-city","IoT"],"slug":"autonomous-libraries","thumb":{"src":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-320.png","srcSet":[{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-320.png","size":320},{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-640.png","size":640},{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-autonomous-libraries.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-320.png","srcSet":[{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-320.png","size":320},{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-640.png","size":640},{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-320.png","srcSet":[{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-320.png","size":320},{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-640.png","size":640},{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-image2.png","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559521image3.gif","srcSet":[{"path":"images/amir_houieh-1761412559521image3.gif","size":600}],"caption":null,"alt":"Autonomous Libraries-image3.gif","order":-1,"r":1.5}],"stack":["Word2Vec","Elasticsearch","OCR","CV","NLP","OpenPose","YOLOv3","LSTMs","TensorFlow","AR interfaces","modular architecture","HCI"],"dateString":"2020","dataYear":2020,"videos":[]}},"__N_SSG":true}