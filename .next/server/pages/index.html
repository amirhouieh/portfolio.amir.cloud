<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Amir Houieh / highlighted projects</title><meta name="keywords" content="amir houieh, amirhouieh"/><meta name="description" content="This is a showcase for highlighted projects by Amir Houieh...."/><meta name="copyright" content="amir.cloud"/><meta name="language" content="EN"/><meta name="Classification" content="Design/Programming"/><meta name="author" content="Amir, amir.houieh@gmail.com"/><meta name="designer" content="amir houieh"/><meta name="owner" content="amir houieh"/><meta name="url" content="https://portfolio.amir.cloud"/><meta name="identifier-URL" content="https://portfolio.amir.cloud"/><meta property="og:title" content="Amir Houieh / highlighted projects"/><meta property="og:url" content="https://portfolio.amir.cloud"/><meta property="og:image" content="https://portfolio.amir.cloud/site-thumb-new.png"/><meta property="og:site_name" content="amir houieh"/><meta property="og:type" content="website"/><meta property="og:description" content="This is a showcase for highlighted projects by Amir Houieh...."/><meta name="twitter:image" content="https://portfolio.amir.cloud/site-thumb-new.png"/><meta itemProp="name" content="https://portfolio.amir.cloud"/><meta itemProp="description" content="This is a showcase for highlighted projects by Amir Houieh...."/><meta itemProp="image" content="https://portfolio.amir.cloud/site-thumb-new.png"/><script type="application/ld+json">
              {
                &quot;@context&quot;: &quot;https://json-ld.org/contexts/person.jsonld&quot;,
                &quot;name&quot;: &quot;Amir Houieh&quot;,
                &quot;born&quot;: &quot;1987-03-22&quot;,
                &quot;url&quot;: &quot;amir.houieh&quot;,
                &quot;contactPoint&quot;: {
                  &quot;@type&quot;: &quot;ContactPoint&quot;,
                  &quot;availableLanguage&quot;: [&quot;English&quot;]
                },
                  &quot;sameAs&quot;: [
                  &quot;https://www.linkedin.com/in/amirhouieh&quot;,
                  &quot;https://github.com/amirhouieh&quot;,
                  &quot;https://vimeo.com/user13046302&quot;,
                  &quot;https://twitter.com/amirhouieh&quot;
                ]
              }
        </script><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/89f6c9f565961e37.css" as="style"/><link rel="stylesheet" href="/_next/static/css/89f6c9f565961e37.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-96470c7b0317e27e.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-a16c617c42bd88d0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3e399e5cc9feb1c1.js" defer=""></script><script src="/_next/static/chunks/63-071348b73b9c6dd3.js" defer=""></script><script src="/_next/static/chunks/984-a8b69ab87f1229c4.js" defer=""></script><script src="/_next/static/chunks/pages/index-12b74bdc05b803bf.js" defer=""></script><script src="/_next/static/aqAUvMRKsTzW4luGvoG2f/_buildManifest.js" defer=""></script><script src="/_next/static/aqAUvMRKsTzW4luGvoG2f/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><div class="blur" font-size="36" style="text-shadow:0 0 50px blue;color:transparent;display:inline-block"><a href="/"><h2 class="page-info">/</h2></a><a title="about me" href="https://amir.cloud"><small>Amir Gorbani Houieh</small></a></div><p class="bio" style="font-size:14px;line-height:1.6;margin-top:15px;max-width:500px">I&#x27;m a founder and engineer working on adaptive systems, memory, and generative intelligence ‚Äî basically making AI less artificial.<br/><br/>I founded <a href="https://suslib.com" target="_blank" style="color:blue">Suslib</a>, an R&amp;D lab blending ML, HCI, and smart environments, and now <a href="https://unbody.io" target="_blank" style="color:blue">Unbody</a>, an open-source and SaaS stack for AI-native development ‚Äî covering RAG, memory, and tool calling.</p><br/><br/><br/><div class="container home"><div class="main-layout"><div class="projects-column"><section class="projectListWrapper"><small class="sans-serif section-title">AI &amp; Machine Learning</small><br/><div class="grid projectList"><div class="page-thumbnail"><div class="blur" font-size="36" title="gray" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/gray/"></a><code class="date">2024</code><h2 class="page-info">Gray</h2><div class="tags"><i>AI-native</i>, <i>blogging framework</i>, <i>open-source</i>, <i>contextual reading</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">AI-native blogging framework that makes reading contextual and dynamic with semantic search and generative content exploration.</div></div><a style="display:none" href="/gray/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="autonomous-libraries" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/autonomous-libraries/"></a><code class="date">2020</code><h2 class="page-info">Autonomous Libraries</h2><div class="tags"><i>R&D</i>, <i>future-of-knowledge</i>, <i>smart-city</i>, <i>IoT</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">R&amp;D project reimagining libraries as distributed networks of hybrid knowledge spaces with AI-powered semantic search and AR interfaces.</div></div><a style="display:none" href="/autonomous-libraries/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="iaa-(inventory-assistant-application)" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/iaa-(inventory-assistant-application)/"></a><code class="date">2020</code><h2 class="page-info">IAA (Inventory Assistant Application)</h2><div class="tags"><i>AR</i>, <i>ML</i>, <i>inventory management</i>, <i>mobile app</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">AR mobile app for inventory management using camera-first design and ML to identify objects and generate metadata on the fly.</div></div><a style="display:none" href="/iaa-(inventory-assistant-application)/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="intention-recognition" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/intention-recognition/"></a><code class="date">2019</code><h2 class="page-info">Intention Recognition</h2><div class="tags"><i>AI</i>, <i>computer-vision</i>, <i>gesture recognition</i>, <i>HCI</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">AI system for gesture and object interaction using computer vision to control digital systems through natural hand movements and gestures.</div></div><a style="display:none" href="/intention-recognition/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="knowledge-recognition" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/knowledge-recognition/"></a><code class="date">2018</code><h2 class="page-info">Knowledge Recognition</h2><div class="tags"><i>AI</i>, <i>semantic-search</i>, <i>ML</i>, <i>knowledge systems</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">AI-powered semantic search system that transforms collections into networks of meaning using computer vision and NLP.</div></div><a style="display:none" href="/knowledge-recognition/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="noui" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/noui/"></a><code class="date">2020</code><h2 class="page-info">noui</h2><div class="tags"><i>Experiment</i>, <i>Machine Learning</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">Machine learning experiments exploring the future of UI/UX design using StyleGAN2 and Pix2Pix for automated interface generation.</div></div><a style="display:none" href="/noui/"></a></div></div><br/><br/><br/><small class="sans-serif section-title">Creative Tools &amp; Platforms</small><div class="grid projectList"><div class="page-thumbnail"><div class="blur" font-size="36" title="took.wiki" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/took.wiki"></a><code class="date">2021</code><h2 class="page-info">TOOK.wiki</h2><div class="tags"><i>research</i>, <i>online platform</i>, <i>Experimental publishing</i>, <i>Indie making</i></div></div></div><a style="display:none" href="/took.wiki"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="i-see-that-i-see-what-you-do-not-see" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/i-see-that-i-see-what-you-do-not-see/"></a><code class="date">2019</code><h2 class="page-info">I See That I See What You Do not See</h2><div class="tags"><i>generative typography</i>, <i>interactive typography</i></div></div></div><a style="display:none" href="/i-see-that-i-see-what-you-do-not-see/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="openrndr.org" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/openrndr.org"></a><code class="date">2018</code><h2 class="page-info">OPENRNDR.org</h2><div class="tags"><i>web application</i></div></div></div><a style="display:none" href="/openrndr.org"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="rexperimental-framework" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/rexperimental-framework/"></a><code class="date">2016</code><h2 class="page-info">Rexperimental Framework</h2><div class="tags"><i>workshop</i>, <i>Lecture</i></div></div></div><a style="display:none" href="/rexperimental-framework/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="running-out" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/running-out/"></a><code class="date">2016</code><h2 class="page-info">Running Out</h2><div class="tags"><i>real-time data</i>, <i>installation</i>, <i>sustainability</i></div></div></div><a style="display:none" href="/running-out/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="pixelator" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/pixelator/"></a><code class="date">2015</code><h2 class="page-info">Pixelator</h2><div class="tags"><i>generative type</i>, <i>alternative tool</i></div></div></div><a style="display:none" href="/pixelator/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="tomorrow-book" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/tomorrow-book/"></a><code class="date">2015</code><h2 class="page-info">Tomorrow Book</h2><div class="tags"><i>research</i>, <i>website</i></div></div></div><a style="display:none" href="/tomorrow-book/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="text-and-space" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/text-and-space/"></a><code class="date">2014</code><h2 class="page-info">Text &amp; Space</h2><div class="tags"><i>data visualization</i>, <i>installation</i></div></div></div><a style="display:none" href="/text-and-space/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="1-week-of-my-life-publication" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/1-week-of-my-life-publication/"></a><code class="date">2013</code><h2 class="page-info">1 week of my life / publication</h2><div class="tags"><i>generative book</i>, <i>alternative tool</i></div></div></div><a style="display:none" href="/1-week-of-my-life-publication/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="2001-a-space-odyssey-poster-series" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/2001-a-space-odyssey-poster-series/"></a><code class="date">2013</code><h2 class="page-info">2001 a space odyssey / poster series</h2><div class="tags"><i>generative poster</i>, <i>alternative tool</i></div></div></div><a style="display:none" href="/2001-a-space-odyssey-poster-series/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="project-indefensible" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/project-indefensible/"></a><code class="date">2016</code><h2 class="page-info">Project Indefensible</h2><div class="tags"><i>website</i>, <i>publishing platform</i></div></div></div><a style="display:none" href="/project-indefensible/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="isia-urbino-digital-platform" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/isia-urbino-digital-platform/"></a><code class="date">2020</code><h2 class="page-info">ISIA Urbino Digital Platform</h2><div class="tags"><i>website</i>, <i>publishing platform</i></div></div></div><a style="display:none" href="/isia-urbino-digital-platform/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="the-25th-hour" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/the-25th-hour/"></a><code class="date">2018</code><h2 class="page-info">The 25th Hour</h2><div class="tags"><i>data visualization</i>, <i>webGl</i>, <i>map visualization</i></div></div></div><a style="display:none" href="/the-25th-hour/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="re" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/re/"></a><code class="date">2016</code><h2 class="page-info">Re-</h2><div class="tags"><i>experimental publishing</i>, <i>software</i>, <i>DIY tool</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">Modular web browser that empowers users to customize content consumption and cut through webpage noise with content modules.</div></div><a style="display:none" href="/re/"></a></div><div class="page-thumbnail"><div class="blur" font-size="36" title="pages" style="text-shadow:0 0 50px #0000FF;color:transparent;display:inline-block"><div class="page-header"><a style="display:none" href="/pages/"></a><code class="date">2016-2017</code><h2 class="page-info">Pages</h2><div class="tags"><i>website</i>, <i>publishing platform</i></div></div><div class="blurb" style="font-size:13px;margin-top:5px;line-height:1.4;font-family:sans-serif">Bilingual publishing platform for collaborative archiving with automated mailing system and direct author access.</div></div><a style="display:none" href="/pages/"></a></div></div></section></div><div class="image-display-column"></div></div><footer class="sans-serif"><span class="sans-serif section-title">Get in touch üëã</span><br/><small><a href="javascript:;">amir.houieh@gmail.com</a></small><small><a href="https://github.com/amirhouieh/">Github</a>, </small><small><a href="https://twitter.com/amirhouieh">Twitter</a>, </small><small><a href="https://www.linkedin.com/in/amirhouieh/">Linkedin</a></small></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"projects":[{"html":"\u003cp\u003e\u003ca href=\"https://took.wiki\"\u003etook.wiki\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTOOK is an online reader generator that uses Wikipedia as its knowledge source. You can upload a text file (e.g: an article, a book, etc), and TOOK creates a new narrative based on important/relevant entities and keywords contextualized with Wikipedia articles.\u003c/p\u003e\n\u003cp\u003eFurthermore, you could also publish your reader with ‚ù§Ô∏è and so it becomes available for everyone else.\u003c/p\u003e\n\u003cp\u003eThe current version uses exact same algorithm for entity extraction, relevancy evaluation but is different in Technology. In the background, there is no use of advanced technologies such as NLP. It is purely the results of a semantic system and mechanism written in code.\u003c/p\u003e\n\u003ch4\u003eBackground\u003c/h4\u003e\n\u003cp\u003eTook is an upgraded version of an old design research project about the future of reading with the title of \u0026quot;Tomorrow Book\u0026quot;. Read more \u003ca href=\"https://portfolio.amir.cloud/tomorrow-book/\"\u003ehere\u003c/a\u003e\u003c/p\u003e\n\u003ch4\u003eAdiotional note\u003c/h4\u003e\n","title":"TOOK.wiki","description":"\u003cp\u003eThe current version uses exact same algorithm for entity extraction, relevancy evaluation but is different in Technology. In the background, there is no use of advanced technologies such as NLP. It is purely the results of a semantic system and mechanism written in code.\u003c/p\u003e\n","tags":["research","online platform","Experimental publishing","Indie making"],"slug":"took.wiki","thumb":{"src":"images/amir_houieh-JBQe5nphNT1NS2UvREHyo-320.png","srcSet":[{"path":"images/amir_houieh-JBQe5nphNT1NS2UvREHyo-320.png","size":320},{"path":"images/amir_houieh-JBQe5nphNT1NS2UvREHyo-640.png","size":640},{"path":"images/amir_houieh-JBQe5nphNT1NS2UvREHyo-1024.png","size":1024}],"caption":null,"alt":"TOOK.wiki-tomorrow-book.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-F62K0483CQ93w2rY6qn34-320.jpg","srcSet":[{"path":"images/amir_houieh-F62K0483CQ93w2rY6qn34-320.jpg","size":320},{"path":"images/amir_houieh-F62K0483CQ93w2rY6qn34-640.jpg","size":640},{"path":"images/amir_houieh-F62K0483CQ93w2rY6qn34-1024.jpg","size":1024}],"caption":null,"alt":"TOOK.wiki-5-image7.jpg","order":5,"r":1.5}],"stack":["Typescript","Next.js","Firebase"],"dateString":"2021","dataYear":2021,"videos":[],"order":10001},{"html":"\u003cp\u003eGray is an AI-native, open-source blogging framework that makes reading more contextual and dynamic.\u003c/p\u003e\n\u003cp\u003eAI has transformed writing, and now it\u0026#39;s time to enhance reading. Gray is an AI-native, open-source blogging framework built in NextJs and powered by Unbody.io. Gray makes reading more contextual and dynamic. Designed for both content creators and readers, Gray brings articles, podcasts and video blogs to life, turning reading into an interactive, personalized experience.\u003c/p\u003e\n\u003ch2\u003ePurpose\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eExploration and Experimentation\u003c/strong\u003e: Gray uses AI to explore new ways of engaging readers, adapting content to their context and preferences.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDynamic and Contextual Reading\u003c/strong\u003e: Gray aims to personalize the reading experience, making content feel specifically tailored and relevant to each user.\u003c/p\u003e\n\u003ch2\u003eFeatures\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eAI-enabled content creation\u003c/strong\u003e: Gray generates metadata and required context based on the blog\u0026#39;s content for various purposes such as SEO and search prompts enhancement.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eAI-enabled content curation\u003c/strong\u003e: Gray categorizes blog posts into creatively constructed categories to promote exploration.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSemantic search\u003c/strong\u003e: Users can search through the posts and within a post using natural language.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGenerative search\u003c/strong\u003e: Users can use the search bar to search, explore, or even chat with the blog. Gray can handle any form of query in natural language, whether it\u0026#39;s a simple concept or a complex task. Some example queries include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eComparing Amir\u0026#39;s posts about AI native apps with Tomas\u0026#39;s presentation.\u003c/li\u003e\n\u003cli\u003eQuerying the future of mobility.\u003c/li\u003e\n\u003cli\u003eAsking about the main topics on the blog.\u003c/li\u003e\n\u003cli\u003eSeeking reading suggestions based on a positive sentiment about AI.\u003c/li\u003e\n\u003c/ul\u003e\n","link":"https://github.com/unbody-io/Gray","title":"Gray","description":"\u003cp\u003eAI has transformed writing, and now it\u0026#39;s time to enhance reading. Gray is an AI-native, open-source blogging framework built in NextJs and powered by Unbody.io. Gray makes reading more contextual and dynamic. Designed for both content creators and readers, Gray brings articles, podcasts and video blogs to life, turning reading into an interactive, personalized experience.\u003c/p\u003e\n","blurb":"AI-native blogging framework that makes reading contextual and dynamic with semantic search and generative content exploration.","tags":["AI-native","blogging framework","open-source","contextual reading"],"slug":"gray","thumb":{"src":"images/amir_houieh-7B8gfWS04O2KDS2PQ6bSf-320.png","srcSet":[{"path":"images/amir_houieh-7B8gfWS04O2KDS2PQ6bSf-320.png","size":320},{"path":"images/amir_houieh-7B8gfWS04O2KDS2PQ6bSf-640.png","size":640},{"path":"images/amir_houieh-7B8gfWS04O2KDS2PQ6bSf-1024.png","size":1024}],"caption":null,"alt":"Gray-gray.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-MxvquaR9JrrCCDmIBuzT5-320.png","srcSet":[{"path":"images/amir_houieh-MxvquaR9JrrCCDmIBuzT5-320.png","size":320},{"path":"images/amir_houieh-MxvquaR9JrrCCDmIBuzT5-640.png","size":640},{"path":"images/amir_houieh-MxvquaR9JrrCCDmIBuzT5-1024.png","size":1024}],"caption":null,"alt":"Gray-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-MyjhWpzya8-Ahrphl-tFQ-320.png","srcSet":[{"path":"images/amir_houieh-MyjhWpzya8-Ahrphl-tFQ-320.png","size":320},{"path":"images/amir_houieh-MyjhWpzya8-Ahrphl-tFQ-640.png","size":640},{"path":"images/amir_houieh-MyjhWpzya8-Ahrphl-tFQ-1024.png","size":1024}],"caption":null,"alt":"Gray-image2.png","order":-1,"r":1.5},{"src":"images/amir_houieh-ccJ7AdgusRDHMAbMFefiI-320.png","srcSet":[{"path":"images/amir_houieh-ccJ7AdgusRDHMAbMFefiI-320.png","size":320},{"path":"images/amir_houieh-ccJ7AdgusRDHMAbMFefiI-640.png","size":640},{"path":"images/amir_houieh-ccJ7AdgusRDHMAbMFefiI-1024.png","size":1024}],"caption":null,"alt":"Gray-image3.png","order":-1,"r":1.5}],"stack":["Unbody","NextJs","ShadCN"],"dateString":"2024","dataYear":2024,"videos":[]},{"html":"\u003cp\u003eAutonomous Libraries (AL) was an R\u0026amp;D project where we asked: what would a library look like if we designed it from scratch for the age of digital knowledge production? Instead of one big central building, AL imagined a distributed network of hybrid knowledge spaces ‚Äî modular, self-managed, community-run, and spread across everyday environments like coffeehouses, squares, or train stations.\u003c/p\u003e\n\u003cp\u003eWe combined all the core technologies we had developed at Suslib ‚Äî Knowledge Recognition for semantic search and contextual linking, Intention Recognition for gesture- and object-based interaction, and lightweight AR interfaces to connect digital and physical resources. The result was a new kind of space: one where you could pick up a book and instantly see its digital context, annotate a page with thoughts and images, or continue reading seamlessly on your device after leaving.\u003c/p\u003e\n\u003cp\u003eAs a team, we treated AL as both a design research exercise and a technological prototype. I led the engineering direction, ensuring our APIs and ML systems could integrate into a hybrid physical-digital environment, while collaborating closely with Martijn on interaction design and Studio Helioripple on modular architectural systems.\u003c/p\u003e\n\u003cp\u003eAL was never meant to be a single app or product, but a vision of community-driven, resilient, non-commercial knowledge infrastructure ‚Äî one that could exist anywhere in the city, belong to everyone, and evolve with new forms of knowledge production.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://suslib.com\"\u003eMartijn de Heer\u003c/a\u003e (co-founder, designer), \u003ca href=\"https://suslib.com\"\u003eStudio Helioripple\u003c/a\u003e (Amin Bahrami)\u003c/p\u003e\n","link":"https://suslib.com/research/autonomous-libraries","title":"Autonomous Libraries","description":"\u003cp\u003eWe combined all the core technologies we had developed at Suslib ‚Äî Knowledge Recognition for semantic search and contextual linking, Intention Recognition for gesture- and object-based interaction, and lightweight AR interfaces to connect digital and physical resources. The result was a new kind of space: one where you could pick up a book and instantly see its digital context, annotate a page with thoughts and images, or continue reading seamlessly on your device after leaving.\u003c/p\u003e\n","blurb":"R\u0026D project reimagining libraries as distributed networks of hybrid knowledge spaces with AI-powered semantic search and AR interfaces.","tags":["R\u0026D","future-of-knowledge","smart-city","IoT"],"slug":"autonomous-libraries","thumb":{"src":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-320.png","srcSet":[{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-320.png","size":320},{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-640.png","size":640},{"path":"images/amir_houieh-AnbUFmwp0A_P0bZcEy_wb-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-autonomous-libraries.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-320.png","srcSet":[{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-320.png","size":320},{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-640.png","size":640},{"path":"images/amir_houieh-24xP0nICpSQRQkoS23c8z-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-320.png","srcSet":[{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-320.png","size":320},{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-640.png","size":640},{"path":"images/amir_houieh-hnRWBuyAArRMpr4v2Jpzo-1024.png","size":1024}],"caption":null,"alt":"Autonomous Libraries-image2.png","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559521image3.gif","srcSet":[{"path":"images/amir_houieh-1761412559521image3.gif","size":600}],"caption":null,"alt":"Autonomous Libraries-image3.gif","order":-1,"r":1.5}],"stack":["Word2Vec","Elasticsearch","OCR","CV","NLP","OpenPose","YOLOv3","LSTMs","TensorFlow","AR interfaces","modular architecture","HCI"],"dateString":"2020","dataYear":2020,"videos":[]},{"html":"\u003cp\u003eIAA started as a side experiment to test what our Knowledge Recognition API could do in practice ‚Äî and quickly grew into a full product. The idea was simple but powerful: point your tablet\u0026#39;s camera at an object in a collection, and instantly know whether it\u0026#39;s already in the inventory, check it in or out, or add it with enriched metadata generated on the fly.\u003c/p\u003e\n\u003cp\u003eWe built IAA for Android and iOS tablets with a \u003cstrong\u003ecamera-first design\u003c/strong\u003e. Instead of clunky forms or RFID scanners, the AR camera was the main interface. It recognized objects, suggested descriptions using ML, and made collection management as easy as taking a photo. Under the hood it leaned on our KR API ‚Äî combining Word2Vec + Elasticsearch for semantic search with computer vision models to identify assets visually.\u003c/p\u003e\n\u003cp\u003eI led the product engineering and development team through multiple iterations: from concept (literally training on the combined bookcases of our team) to web-based prototypes, and finally to the beta version that people could register to try. By 2022, we launched version 1.0 for both iOS and Android, shaped heavily by user feedback.\u003c/p\u003e\n\u003cp\u003eIAA was the first time we turned our research into a \u003cstrong\u003eworking, usable product\u003c/strong\u003e. It proved that our backend technology could actually make life easier for real people managing collections ‚Äî librarians, archivists, or anyone dealing with physical and digital assets. For me, it was a huge milestone: going from experimental APIs to a polished, camera-driven app that people could actually use.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://suslib.com\"\u003eMartijn de Heer\u003c/a\u003e\u003c/p\u003e\n","link":"https://suslib.com/solution/inventory-assistant","title":"IAA (Inventory Assistant Application)","description":"\u003cp\u003eWe built IAA for Android and iOS tablets with a \u003cstrong\u003ecamera-first design\u003c/strong\u003e. Instead of clunky forms or RFID scanners, the AR camera was the main interface. It recognized objects, suggested descriptions using ML, and made collection management as easy as taking a photo. Under the hood it leaned on our KR API ‚Äî combining Word2Vec + Elasticsearch for semantic search with computer vision models to identify assets visually.\u003c/p\u003e\n","blurb":"AR mobile app for inventory management using camera-first design and ML to identify objects and generate metadata on the fly.","tags":["AR","ML","inventory management","mobile app"],"slug":"iaa-(inventory-assistant-application)","thumb":{"src":"images/amir_houieh-sGe8T4nBnyBBrJqdwWWnP-320.png","srcSet":[{"path":"images/amir_houieh-sGe8T4nBnyBBrJqdwWWnP-320.png","size":320},{"path":"images/amir_houieh-sGe8T4nBnyBBrJqdwWWnP-640.png","size":640},{"path":"images/amir_houieh-sGe8T4nBnyBBrJqdwWWnP-1024.png","size":1024}],"caption":null,"alt":"IAA (Inventory Assistant Application)-inventory-assistant-application.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-9tcQRbv9iP-5AVCP85l3J-320.png","srcSet":[{"path":"images/amir_houieh-9tcQRbv9iP-5AVCP85l3J-320.png","size":320},{"path":"images/amir_houieh-9tcQRbv9iP-5AVCP85l3J-640.png","size":640},{"path":"images/amir_houieh-9tcQRbv9iP-5AVCP85l3J-1024.png","size":1024}],"caption":null,"alt":"IAA (Inventory Assistant Application)-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-e6FQY9VfYhJ8R-Wk5JVSn-320.png","srcSet":[{"path":"images/amir_houieh-e6FQY9VfYhJ8R-Wk5JVSn-320.png","size":320},{"path":"images/amir_houieh-e6FQY9VfYhJ8R-Wk5JVSn-640.png","size":640},{"path":"images/amir_houieh-e6FQY9VfYhJ8R-Wk5JVSn-1024.png","size":1024}],"caption":null,"alt":"IAA (Inventory Assistant Application)-image2.png","order":-1,"r":1.5}],"stack":["ARKit/ARCore","Knowledge Recognition API","TensorFlow","Elasticsearch","REST API"],"dateString":"2020","dataYear":2020,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://triennale2019.hetnieuweinstituut.nl\"\u003etriennale2019.hetnieuweinstituut.nl\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://studiomoniker.com\"\u003e\u003ccode\u003eStudio Moniker\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eSmall but exciting project in collaboration with Studio Moniker. This is an interactive typographic webcover designed by Rudy Guedj, and programmed by me. (made by p5JS and opentype-js).\u003c/p\u003e\n","title":"I See That I See What You Do not See","description":"\u003cp\u003eSmall but exciting project in collaboration with Studio Moniker. This is an interactive typographic webcover designed by Rudy Guedj, and programmed by me. (made by p5JS and opentype-js).\u003c/p\u003e\n","tags":["generative typography","interactive typography"],"slug":"i-see-that-i-see-what-you-do-not-see","thumb":{"src":"images/amir_houieh-1761412559384ezgif-2-5d1a1d20bc1c.gif","srcSet":[{"path":"images/amir_houieh-1761412559384ezgif-2-5d1a1d20bc1c.gif","size":600}],"caption":null,"alt":"I See That I See What You Do not See-ezgif-2-5d1a1d20bc1c.gif","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-1761412559431ezgif-2-000c12fab057.gif","srcSet":[{"path":"images/amir_houieh-1761412559431ezgif-2-000c12fab057.gif","size":600}],"caption":null,"alt":"I See That I See What You Do not See-ezgif-2-000c12fab057.gif","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559436ezgif-2-77f92584bbca.gif","srcSet":[{"path":"images/amir_houieh-1761412559436ezgif-2-77f92584bbca.gif","size":600}],"caption":null,"alt":"I See That I See What You Do not See-ezgif-2-77f92584bbca.gif","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559439ezgif-2-c9dbd1cd888a.gif","srcSet":[{"path":"images/amir_houieh-1761412559439ezgif-2-c9dbd1cd888a.gif","size":600}],"caption":null,"alt":"I See That I See What You Do not See-ezgif-2-c9dbd1cd888a.gif","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559441ezgif-2-f435cc0528b8.gif","srcSet":[{"path":"images/amir_houieh-1761412559441ezgif-2-f435cc0528b8.gif","size":600}],"caption":null,"alt":"I See That I See What You Do not See-ezgif-2-f435cc0528b8.gif","order":-1,"r":1.5}],"stack":["es6","html/css","p5js","webpack"],"dateString":"2019","dataYear":2019,"videos":[]},{"html":"\u003cp\u003eIf my KR project was about making collections smart, Intention Recognition was about making them playful. We wanted people to control digital systems with nothing more than gestures and the way they handled objects. Pick up a book, wave your hand, flip through pages ‚Äî and the system responds.\u003c/p\u003e\n\u003cp\u003eTechnically, it was a fun mess. We used OpenPose for skeleton tracking, dlib for facial gestures, YOLOv3 for object detection, and LSTMs in TensorFlow to capture sequences of movement. I helped design the system and API, while our ML engineer went deep into dataset training ‚Äî over 100k labeled clips. I jumped in on dataset curation too, which was both painful and weirdly satisfying.\u003c/p\u003e\n\u003cp\u003eWhat made IR special was combining gestures with object interactions. It wasn\u0026#39;t just about waving at a camera ‚Äî it was about how you handled things in the real world. We even built an \u0026quot;observer mode\u0026quot; where the system could notice new gestures and adapt over time. In demos, people loved teaching it something on the spot and seeing it respond.\u003c/p\u003e\n\u003cp\u003eWe made it work on cheap hardware: regular webcams streaming over WebRTC, models optimized with TensorRT to run on Jetson Nanos and Raspberry Pis. No special sensors, no Kinect-style setup ‚Äî just software magic.\u003c/p\u003e\n\u003cp\u003eIR ended up being showcased in libraries, exhibitions, and design festivals. It was the project that made people literally laugh and smile in front of our booth, waving their hands around like kids. For me, it was proof that futuristic interaction doesn\u0026#39;t need futuristic hardware ‚Äî just the right mix of vision, scrappiness, and teamwork.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://suslib.com\"\u003eMartijn de Heer\u003c/a\u003e, \u003ca href=\"https://suslib.com\"\u003eHomayoun Moradi\u003c/a\u003e\u003c/p\u003e\n","link":"https://suslib.com/core/intention-recognition","title":"Intention Recognition","description":"\u003cp\u003eTechnically, it was a fun mess. We used OpenPose for skeleton tracking, dlib for facial gestures, YOLOv3 for object detection, and LSTMs in TensorFlow to capture sequences of movement. I helped design the system and API, while our ML engineer went deep into dataset training ‚Äî over 100k labeled clips. I jumped in on dataset curation too, which was both painful and weirdly satisfying.\u003c/p\u003e\n","blurb":"AI system for gesture and object interaction using computer vision to control digital systems through natural hand movements and gestures.","tags":["AI","computer-vision","gesture recognition","HCI"],"slug":"intention-recognition","thumb":{"src":"images/amir_houieh-lmKF5ZOrK_nYknRso-zys-320.jpg","srcSet":[{"path":"images/amir_houieh-lmKF5ZOrK_nYknRso-zys-320.jpg","size":320},{"path":"images/amir_houieh-lmKF5ZOrK_nYknRso-zys-640.jpg","size":640},{"path":"images/amir_houieh-lmKF5ZOrK_nYknRso-zys-1024.jpg","size":1024}],"caption":null,"alt":"Intention Recognition-intention-recognition.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-D8IU9Q4u2qB-6vaoqgVMc-320.png","srcSet":[{"path":"images/amir_houieh-D8IU9Q4u2qB-6vaoqgVMc-320.png","size":320},{"path":"images/amir_houieh-D8IU9Q4u2qB-6vaoqgVMc-640.png","size":640},{"path":"images/amir_houieh-D8IU9Q4u2qB-6vaoqgVMc-1024.png","size":1024}],"caption":null,"alt":"Intention Recognition-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-ay5nvpIInsdfC7EgJhjfy-320.jpg","srcSet":[{"path":"images/amir_houieh-ay5nvpIInsdfC7EgJhjfy-320.jpg","size":320},{"path":"images/amir_houieh-ay5nvpIInsdfC7EgJhjfy-640.jpg","size":640},{"path":"images/amir_houieh-ay5nvpIInsdfC7EgJhjfy-1024.jpg","size":1024}],"caption":null,"alt":"Intention Recognition-image2.jpg","order":-1,"r":1.5}],"stack":["OpenPose","dlib","YOLOv3","LSTM","TensorFlow","TensorRT","WebRTC","Jetson Nano","Raspberry Pi"],"dateString":"2019","dataYear":2019,"videos":[]},{"html":"\u003cp\u003eKR was our first big experiment at \u003ca href=\"https://suslib.com\"\u003eSuslib\u003c/a\u003e. The idea was simple: what if a collection of books, images, or files could actually understand itself? Instead of being a flat archive, it would be a network of meaning that you could search semantically and explore contextually.\u003c/p\u003e\n\u003cp\u003eThis was 2018, so we didn\u0026#39;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word2Vec embeddings and dropped them into Elasticsearch to give collections a \u0026quot;search by idea\u0026quot; capability. It felt like hacking the future together with duct tape and GPUs.\u003c/p\u003e\n\u003cp\u003eI led the team that built it ‚Äî backend, ML, and MLOps engineers ‚Äî and my role was to drive the product architecture, glue all the moving parts, and also get my hands dirty with model training and pipeline design. We wrapped it all into a REST and streaming API that sat neatly between a CMS and database. That made it lightweight, flexible, and fast enough to power our own AR inventory app while still being useful for outside developers.\u003c/p\u003e\n\u003cp\u003eLooking back, KR was the project that put us on the map: it got us into Dutch Design Week, helped us secure funding, and proved that we could build practical AI-driven knowledge systems before the ecosystem was ready for it.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://suslib.com\"\u003eMartijn de Heer\u003c/a\u003e, \u003ca href=\"https://suslib.com\"\u003eHomayoun Moradi\u003c/a\u003e\u003c/p\u003e\n","link":"https://suslib.com/core/knowledge-recognition","title":"Knowledge Recognition","description":"\u003cp\u003eThis was 2018, so we didn\u0026#39;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word2Vec embeddings and dropped them into Elasticsearch to give collections a \u0026quot;search by idea\u0026quot; capability. It felt like hacking the future together with duct tape and GPUs.\u003c/p\u003e\n","blurb":"AI-powered semantic search system that transforms collections into networks of meaning using computer vision and NLP.","tags":["AI","semantic-search","ML","knowledge systems"],"slug":"knowledge-recognition","thumb":{"src":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png","srcSet":[{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png","size":320},{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-640.png","size":640},{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-knowledge-recognition.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png","srcSet":[{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png","size":320},{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-640.png","size":640},{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png","srcSet":[{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png","size":320},{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-640.png","size":640},{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image2.png","order":-1,"r":1.5},{"src":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png","srcSet":[{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png","size":320},{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-640.png","size":640},{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image3.png","order":-1,"r":1.5},{"src":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png","srcSet":[{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png","size":320},{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-640.png","size":640},{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image4.png","order":-1,"r":1.5},{"src":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png","srcSet":[{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png","size":320},{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-640.png","size":640},{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image5.png","order":-1,"r":1.5}],"stack":["YOLOv3","Mask R-CNN","Tesseract OCR","spaCy","LDA","Word2Vec","Elasticsearch","TensorFlow","PyTorch","REST API","Streaming API"],"dateString":"2018","dataYear":2018,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://openrndr.org\"\u003eopenrndr.org\u003c/a\u003e\nThis is one of the projects which I worked on at RNDR.\u003c/p\u003e\n\u003cp\u003eWebsite for the creative coding framework OPENRNDR.\u003c/p\u003e\n","title":"OPENRNDR.org","description":"\u003cp\u003e\u003ca href=\"https://openrndr.org\"\u003eopenrndr.org\u003c/a\u003e\nThis is one of the projects which I worked on at RNDR.\u003c/p\u003e\n","tags":["web application"],"slug":"openrndr.org","thumb":{"src":"images/amir_houieh-3vXsB0qVoWS-4PyGa6z_9-320.png","srcSet":[{"path":"images/amir_houieh-3vXsB0qVoWS-4PyGa6z_9-320.png","size":320},{"path":"images/amir_houieh-3vXsB0qVoWS-4PyGa6z_9-640.png","size":640},{"path":"images/amir_houieh-3vXsB0qVoWS-4PyGa6z_9-1024.png","size":1024}],"caption":null,"alt":"OPENRNDR.org-Screen Shot 2019-03-12 at 16.39.46.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-AEE7XG7iq4_f1eWYHCyT7-320.png","srcSet":[{"path":"images/amir_houieh-AEE7XG7iq4_f1eWYHCyT7-320.png","size":320},{"path":"images/amir_houieh-AEE7XG7iq4_f1eWYHCyT7-640.png","size":640},{"path":"images/amir_houieh-AEE7XG7iq4_f1eWYHCyT7-1024.png","size":1024}],"caption":null,"alt":"OPENRNDR.org-Screen Shot 2019-03-12 at 16.35.41.png","order":-1,"r":1.5},{"src":"images/amir_houieh-KQPb0pYrizSjzsmPKG79v-320.png","srcSet":[{"path":"images/amir_houieh-KQPb0pYrizSjzsmPKG79v-320.png","size":320},{"path":"images/amir_houieh-KQPb0pYrizSjzsmPKG79v-640.png","size":640},{"path":"images/amir_houieh-KQPb0pYrizSjzsmPKG79v-1024.png","size":1024}],"caption":null,"alt":"OPENRNDR.org-Screen Shot 2019-03-12 at 16.35.47.png","order":-1,"r":1.5},{"src":"images/amir_houieh-l31yJhZ1WqgklJkARpJTx-320.png","srcSet":[{"path":"images/amir_houieh-l31yJhZ1WqgklJkARpJTx-320.png","size":320},{"path":"images/amir_houieh-l31yJhZ1WqgklJkARpJTx-640.png","size":640},{"path":"images/amir_houieh-l31yJhZ1WqgklJkARpJTx-1024.png","size":1024}],"caption":null,"alt":"OPENRNDR.org-Screen Shot 2019-03-12 at 16.35.53.png","order":-1,"r":1.5},{"src":"images/amir_houieh-xaFzsGSc03W0OgLwWcv-t-320.png","srcSet":[{"path":"images/amir_houieh-xaFzsGSc03W0OgLwWcv-t-320.png","size":320},{"path":"images/amir_houieh-xaFzsGSc03W0OgLwWcv-t-640.png","size":640},{"path":"images/amir_houieh-xaFzsGSc03W0OgLwWcv-t-1024.png","size":1024}],"caption":"phone version (menu).png","alt":"phone version (menu).png","order":-1,"r":1.5},{"src":"images/amir_houieh-34LGiOrT_BvgBTeRDmuh4-320.png","srcSet":[{"path":"images/amir_houieh-34LGiOrT_BvgBTeRDmuh4-320.png","size":320},{"path":"images/amir_houieh-34LGiOrT_BvgBTeRDmuh4-640.png","size":640},{"path":"images/amir_houieh-34LGiOrT_BvgBTeRDmuh4-1024.png","size":1024}],"caption":"phone-version.png","alt":"phone-version.png","order":-1,"r":1.5}],"stack":["es6","html/css","TypeScript","React","Netlify","react-static","DatoCMS"],"dateString":"2018","dataYear":2018,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://artexyz.info\"\u003eproject webpage\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eat\u003c/code\u003e \u003ca href=\"https://www.artez.nl/en/course/graphic-design\"\u003e\u003ccode\u003eArtez Graphic design department\u003c/code\u003e\u003c/a\u003e,\u003c/p\u003e\n\u003cp\u003eRexperimental Framework happened as a 4 days workshop given by amir houieh  with BA students from Graphic Design Arnhem, in October 2018 at Artez. The workshop aimed to discuss and develop experimental publishing frameworks in our digital realm based on decentralized and distributed networks. The workshop consist of 4 lectures and one project assignment. The workshop was an extension to REPUB project. The lectures introduces topics such as content flow in digital environments, the fundamental of the web and decentralized networks like p2p.\u003c/p\u003e\n\u003cp\u003eAs the assignment students needed to design an alternative model for content production and consumption as well as distribution in form a publishing framework. In other words they needed to design how users could produce and manage their content as well as how this content is published through a an interface. The distribution part of framework must occur on a decentralized-distributed network.\nAt the end the workshop yields into several different projects which you can read more about on the website of the workshop.\u003c/p\u003e\n","title":"Rexperimental Framework","description":"\u003cp\u003eRexperimental Framework happened as a 4 days workshop given by amir houieh  with BA students from Graphic Design Arnhem, in October 2018 at Artez. The workshop aimed to discuss and develop experimental publishing frameworks in our digital realm based on decentralized and distributed networks. The workshop consist of 4 lectures and one project assignment. The workshop was an extension to REPUB project. The lectures introduces topics such as content flow in digital environments, the fundamental of the web and decentralized networks like p2p.\u003c/p\u003e\n","tags":["workshop","Lecture"],"slug":"rexperimental-framework","thumb":{"src":"images/amir_houieh-D8VcT17cp0LowrddpTQut-320.jpg","srcSet":[{"path":"images/amir_houieh-D8VcT17cp0LowrddpTQut-320.jpg","size":320},{"path":"images/amir_houieh-D8VcT17cp0LowrddpTQut-640.jpg","size":640},{"path":"images/amir_houieh-D8VcT17cp0LowrddpTQut-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-artexyz.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-nV1EqM99bx6OGKOv5rpjr-320.jpg","srcSet":[{"path":"images/amir_houieh-nV1EqM99bx6OGKOv5rpjr-320.jpg","size":320},{"path":"images/amir_houieh-nV1EqM99bx6OGKOv5rpjr-640.jpg","size":640},{"path":"images/amir_houieh-nV1EqM99bx6OGKOv5rpjr-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-1F2XGIUnhF-UrFXFfV8Ou5Z0RtnHj2MWP.jpg","order":1,"r":1.5},{"src":"images/amir_houieh-17614125597221rNHxcSIRJxluRAzciBw0Sk2UHUmUVEGI.gif","srcSet":[{"path":"images/amir_houieh-17614125597221rNHxcSIRJxluRAzciBw0Sk2UHUmUVEGI.gif","size":600}],"caption":null,"alt":"Rexperimental Framework-1rNHxcSIRJxluRAzciBw0Sk2UHUmUVEGI.gif","order":1,"r":1.5},{"src":"images/amir_houieh-XxQCYoKwmZyHT4OBSH1ma-320.jpg","srcSet":[{"path":"images/amir_houieh-XxQCYoKwmZyHT4OBSH1ma-320.jpg","size":320},{"path":"images/amir_houieh-XxQCYoKwmZyHT4OBSH1ma-640.jpg","size":640},{"path":"images/amir_houieh-XxQCYoKwmZyHT4OBSH1ma-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-20181009_140856.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-O3nr0aob53lderxzwvuqM-320.jpg","srcSet":[{"path":"images/amir_houieh-O3nr0aob53lderxzwvuqM-320.jpg","size":320},{"path":"images/amir_houieh-O3nr0aob53lderxzwvuqM-640.jpg","size":640},{"path":"images/amir_houieh-O3nr0aob53lderxzwvuqM-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-20181009_161147_HDR.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-tnrHu-svZLKrNhrQYL-B4-320.jpg","srcSet":[{"path":"images/amir_houieh-tnrHu-svZLKrNhrQYL-B4-320.jpg","size":320},{"path":"images/amir_houieh-tnrHu-svZLKrNhrQYL-B4-640.jpg","size":640},{"path":"images/amir_houieh-tnrHu-svZLKrNhrQYL-B4-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-20181009_164447_HDR.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-lrx8mfx0X6uwDdk9nEh9d-320.jpg","srcSet":[{"path":"images/amir_houieh-lrx8mfx0X6uwDdk9nEh9d-320.jpg","size":320},{"path":"images/amir_houieh-lrx8mfx0X6uwDdk9nEh9d-640.jpg","size":640},{"path":"images/amir_houieh-lrx8mfx0X6uwDdk9nEh9d-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-20181011_171942_HDR.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-rltcJToneb5FkdIYm3roN-320.jpg","srcSet":[{"path":"images/amir_houieh-rltcJToneb5FkdIYm3roN-320.jpg","size":320},{"path":"images/amir_houieh-rltcJToneb5FkdIYm3roN-640.jpg","size":640},{"path":"images/amir_houieh-rltcJToneb5FkdIYm3roN-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-20181011_183205.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-bTNixc7_ClmqrIv3R_tUv-320.jpg","srcSet":[{"path":"images/amir_houieh-bTNixc7_ClmqrIv3R_tUv-320.jpg","size":320},{"path":"images/amir_houieh-bTNixc7_ClmqrIv3R_tUv-640.jpg","size":640},{"path":"images/amir_houieh-bTNixc7_ClmqrIv3R_tUv-1024.jpg","size":1024}],"caption":null,"alt":"Rexperimental Framework-White board - concept.jpg","order":-1,"r":1.5}],"stack":null,"dateString":"2016","dataYear":2016,"videos":[]},{"html":"\u003cp\u003eExhibited at Salone del Mobile, Milano\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"http://www.minddesign.info/\"\u003e\u003ccode\u003eNiels Schrader\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://krks.info/\"\u003e\u003ccode\u003eGabor Kerekes\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"http://veravandeseyp.com\"\u003e\u003ccode\u003eVera van de Seyp\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe installation Running Out by Graphic Design students Amir Houieh, G√°bor Kerekes, and \u003ca href=\"http://veravandeseyp.com\"\u003eVera van de Seyp\u003c/a\u003e, confronts its audience with the consequences of the rapidly increasing electricity consumption. In their research, the students address one of the biggest challenge of the 21st century: the global dependecy on electricity.\nThe work is centered around a dismantled computer screen that displays the CO2 emissions generated by the device itself and a countdown revealing the days left until the world runs out of natural resources (numbers based on projections published at COP21).\nIn fall 2015, the Climate Change Conference took place in Paris. Delegates of all United Nations member countries met to discuss urgent arrangement in relation of climate change. Their discussion resulted in the Paris Agreement that made 196 countries agree upon changing national and international policies for the sake of keeping the damage for the climate as low as possible.\nIf the average temperature in the world rises above 2¬∫C, the damage to the environment is unstoppable and the climate will grow into a vicious circle leading to a rapidly increasing amount of natural disasters. Right now, the average temperature rise is already at 1.5¬∫C and rising steadily. The largest contribution to this increase is the burning of fossil fuels to generate electrical energy.\nAbout a third of the carbon emissions that are generated is created in a domestic environment. This means that all of us contribute with our daily habits.\nThe interfaces through which people get in contact with their energy consumption leaves out all context: the carbon emissions generated by the device, in the home, but also the bigger context. The global change isn‚Äôt visible in the home and the time that is left before the 2¬∫C temperature elevation is crossed partially because of these daily domestic useages.\nWith their project, Houieh, Kerekes and Van de Seyp aim to lay bare how common energy interfaces seem to deliberately cover the urgency of the global energy crisis.\u003c/p\u003e\n\u003cp\u003e\u003cem\u003ePictures by Sem Langendijk and Roel Backaert.\u003c/em\u003e\u003c/p\u003e\n","title":"Running Out","description":"\u003cp\u003eThe installation Running Out by Graphic Design students Amir Houieh, G√°bor Kerekes, and \u003ca href=\"http://veravandeseyp.com\"\u003eVera van de Seyp\u003c/a\u003e, confronts its audience with the consequences of the rapidly increasing electricity consumption. In their research, the students address one of the biggest challenge of the 21st century: the global dependecy on electricity.\nThe work is centered around a dismantled computer screen that displays the CO2 emissions generated by the device itself and a countdown revealing the days left until the world runs out of natural resources (numbers based on projections published at COP21).\nIn fall 2015, the Climate Change Conference took place in Paris. Delegates of all United Nations member countries met to discuss urgent arrangement in relation of climate change. Their discussion resulted in the Paris Agreement that made 196 countries agree upon changing national and international policies for the sake of keeping the damage for the climate as low as possible.\nIf the average temperature in the world rises above 2¬∫C, the damage to the environment is unstoppable and the climate will grow into a vicious circle leading to a rapidly increasing amount of natural disasters. Right now, the average temperature rise is already at 1.5¬∫C and rising steadily. The largest contribution to this increase is the burning of fossil fuels to generate electrical energy.\nAbout a third of the carbon emissions that are generated is created in a domestic environment. This means that all of us contribute with our daily habits.\nThe interfaces through which people get in contact with their energy consumption leaves out all context: the carbon emissions generated by the device, in the home, but also the bigger context. The global change isn‚Äôt visible in the home and the time that is left before the 2¬∫C temperature elevation is crossed partially because of these daily domestic useages.\nWith their project, Houieh, Kerekes and Van de Seyp aim to lay bare how common energy interfaces seem to deliberately cover the urgency of the global energy crisis.\u003c/p\u003e\n","tags":["real-time data","installation","sustainability"],"slug":"running-out","thumb":{"src":"images/amir_houieh-6kDi5j0CCrXGC4OABoKFi-320.jpg","srcSet":[{"path":"images/amir_houieh-6kDi5j0CCrXGC4OABoKFi-320.jpg","size":320},{"path":"images/amir_houieh-6kDi5j0CCrXGC4OABoKFi-640.jpg","size":640},{"path":"images/amir_houieh-6kDi5j0CCrXGC4OABoKFi-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-running-out-project.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-E9E0M0E1iTf7t7jgaErhk-320.jpg","srcSet":[{"path":"images/amir_houieh-E9E0M0E1iTf7t7jgaErhk-320.jpg","size":320},{"path":"images/amir_houieh-E9E0M0E1iTf7t7jgaErhk-640.jpg","size":640},{"path":"images/amir_houieh-E9E0M0E1iTf7t7jgaErhk-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-1-reset-5.jpg","order":1,"r":1.5},{"src":"images/amir_houieh-yZl5aEZ6v96VlwphMi54X-320.jpg","srcSet":[{"path":"images/amir_houieh-yZl5aEZ6v96VlwphMi54X-320.jpg","size":320},{"path":"images/amir_houieh-yZl5aEZ6v96VlwphMi54X-640.jpg","size":640},{"path":"images/amir_houieh-yZl5aEZ6v96VlwphMi54X-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-2-reset-7.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-FykZe4BagT0dELDjHOK8O-320.jpg","srcSet":[{"path":"images/amir_houieh-FykZe4BagT0dELDjHOK8O-320.jpg","size":320},{"path":"images/amir_houieh-FykZe4BagT0dELDjHOK8O-640.jpg","size":640},{"path":"images/amir_houieh-FykZe4BagT0dELDjHOK8O-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-3-reset-8.jpg","order":3,"r":1.5},{"src":"images/amir_houieh-VgB-lvApxdAmeOlE1sp0H-320.jpg","srcSet":[{"path":"images/amir_houieh-VgB-lvApxdAmeOlE1sp0H-320.jpg","size":320},{"path":"images/amir_houieh-VgB-lvApxdAmeOlE1sp0H-640.jpg","size":640},{"path":"images/amir_houieh-VgB-lvApxdAmeOlE1sp0H-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-4-reset-9.jpg","order":4,"r":1.5},{"src":"images/amir_houieh-voA_fsfCwxeqB-TedU-K5-320.jpg","srcSet":[{"path":"images/amir_houieh-voA_fsfCwxeqB-TedU-K5-320.jpg","size":320},{"path":"images/amir_houieh-voA_fsfCwxeqB-TedU-K5-640.jpg","size":640},{"path":"images/amir_houieh-voA_fsfCwxeqB-TedU-K5-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-5-reset-10.jpg","order":5,"r":1.5},{"src":"images/amir_houieh-5PCrM_EPw-8HB-nn1Zw67-320.jpg","srcSet":[{"path":"images/amir_houieh-5PCrM_EPw-8HB-nn1Zw67-320.jpg","size":320},{"path":"images/amir_houieh-5PCrM_EPw-8HB-nn1Zw67-640.jpg","size":640},{"path":"images/amir_houieh-5PCrM_EPw-8HB-nn1Zw67-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-6-reset-11.jpg","order":6,"r":1.5},{"src":"images/amir_houieh--mNRxjKXogcIILw8qo9lV-320.jpg","srcSet":[{"path":"images/amir_houieh--mNRxjKXogcIILw8qo9lV-320.jpg","size":320},{"path":"images/amir_houieh--mNRxjKXogcIILw8qo9lV-640.jpg","size":640},{"path":"images/amir_houieh--mNRxjKXogcIILw8qo9lV-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-7-reset-12.jpg","order":7,"r":1.5},{"src":"images/amir_houieh-6ulcqEoMS5KPFjf88yFOc-320.jpg","srcSet":[{"path":"images/amir_houieh-6ulcqEoMS5KPFjf88yFOc-320.jpg","size":320},{"path":"images/amir_houieh-6ulcqEoMS5KPFjf88yFOc-640.jpg","size":640},{"path":"images/amir_houieh-6ulcqEoMS5KPFjf88yFOc-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-8-reset-6.jpg","order":8,"r":1.5},{"src":"images/amir_houieh-lwz_-N9jqs2DED1uisH3K-320.jpg","srcSet":[{"path":"images/amir_houieh-lwz_-N9jqs2DED1uisH3K-320.jpg","size":320},{"path":"images/amir_houieh-lwz_-N9jqs2DED1uisH3K-640.jpg","size":640},{"path":"images/amir_houieh-lwz_-N9jqs2DED1uisH3K-1024.jpg","size":1024}],"caption":null,"alt":"Running Out-9-reset-13.jpg","order":9,"r":1.5}],"stack":null,"dateString":"2016","dataYear":2016,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://github.com/amirhouieh/type-pixelator\"\u003esource code on Github\u003c/a\u003e\n\u003ca href=\"https://archive.amir.cloud/pixelator/\"\u003earchive.amir.cloud/pixelator\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eA simple \u003ca href=\"http://www.drawbot.com\"\u003eDrawbot\u003c/a\u003e module, pixelating texts.\u003c/p\u003e\n","title":"Pixelator","description":"\u003cp\u003e\u003ca href=\"https://github.com/amirhouieh/type-pixelator\"\u003esource code on Github\u003c/a\u003e\n\u003ca href=\"https://archive.amir.cloud/pixelator/\"\u003earchive.amir.cloud/pixelator\u003c/a\u003e\u003c/p\u003e\n","tags":["generative type","alternative tool"],"slug":"pixelator","thumb":{"src":"images/amir_houieh-8YSWWsbU6Fyy_qycpNpJV-320.png","srcSet":[{"path":"images/amir_houieh-8YSWWsbU6Fyy_qycpNpJV-320.png","size":320},{"path":"images/amir_houieh-8YSWWsbU6Fyy_qycpNpJV-640.png","size":640},{"path":"images/amir_houieh-8YSWWsbU6Fyy_qycpNpJV-1024.png","size":1024}],"caption":null,"alt":"Pixelator-16-2x.png","order":1,"r":1.5},"images":[{"src":"images/amir_houieh-ZvlmoaXHB76jPfrFaBT3t-320.png","srcSet":[{"path":"images/amir_houieh-ZvlmoaXHB76jPfrFaBT3t-320.png","size":320},{"path":"images/amir_houieh-ZvlmoaXHB76jPfrFaBT3t-640.png","size":640},{"path":"images/amir_houieh-ZvlmoaXHB76jPfrFaBT3t-1024.png","size":1024}],"caption":null,"alt":"Pixelator-16-2x.png","order":1,"r":1.5},{"src":"images/amir_houieh-YbhbjwL5IGPxzqGRcKnZV-320.png","srcSet":[{"path":"images/amir_houieh-YbhbjwL5IGPxzqGRcKnZV-320.png","size":320},{"path":"images/amir_houieh-YbhbjwL5IGPxzqGRcKnZV-640.png","size":640},{"path":"images/amir_houieh-YbhbjwL5IGPxzqGRcKnZV-1024.png","size":1024}],"caption":null,"alt":"Pixelator-17-2x.png","order":1,"r":1.5},{"src":"images/amir_houieh-SdU6dr3aJz1kcLNZfSPvZ-320.png","srcSet":[{"path":"images/amir_houieh-SdU6dr3aJz1kcLNZfSPvZ-320.png","size":320},{"path":"images/amir_houieh-SdU6dr3aJz1kcLNZfSPvZ-640.png","size":640},{"path":"images/amir_houieh-SdU6dr3aJz1kcLNZfSPvZ-1024.png","size":1024}],"caption":null,"alt":"Pixelator-20-2x.png","order":2,"r":1.5},{"src":"images/amir_houieh-xVeA91NhHRd031tF_SVwR-320.png","srcSet":[{"path":"images/amir_houieh-xVeA91NhHRd031tF_SVwR-320.png","size":320},{"path":"images/amir_houieh-xVeA91NhHRd031tF_SVwR-640.png","size":640},{"path":"images/amir_houieh-xVeA91NhHRd031tF_SVwR-1024.png","size":1024}],"caption":null,"alt":"Pixelator-21-2x.png","order":2,"r":1.5},{"src":"images/amir_houieh-GId5Q1wkIRn8o3Q7kmaVB-320.png","srcSet":[{"path":"images/amir_houieh-GId5Q1wkIRn8o3Q7kmaVB-320.png","size":320},{"path":"images/amir_houieh-GId5Q1wkIRn8o3Q7kmaVB-640.png","size":640},{"path":"images/amir_houieh-GId5Q1wkIRn8o3Q7kmaVB-1024.png","size":1024}],"caption":null,"alt":"Pixelator-23-2x.png","order":2,"r":1.5},{"src":"images/amir_houieh-o5e8IijnpzLViNlKNCCqD-320.png","srcSet":[{"path":"images/amir_houieh-o5e8IijnpzLViNlKNCCqD-320.png","size":320},{"path":"images/amir_houieh-o5e8IijnpzLViNlKNCCqD-640.png","size":640},{"path":"images/amir_houieh-o5e8IijnpzLViNlKNCCqD-1024.png","size":1024}],"caption":null,"alt":"Pixelator-5-2x.png","order":5,"r":1.5},{"src":"images/amir_houieh-iujFsKmD-4EMQQwWaNTR3-320.png","srcSet":[{"path":"images/amir_houieh-iujFsKmD-4EMQQwWaNTR3-320.png","size":320},{"path":"images/amir_houieh-iujFsKmD-4EMQQwWaNTR3-640.png","size":640},{"path":"images/amir_houieh-iujFsKmD-4EMQQwWaNTR3-1024.png","size":1024}],"caption":null,"alt":"Pixelator-8-2x.png","order":8,"r":1.5}],"stack":["python","drawbot"],"dateString":"2015","dataYear":2015,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://tomorrow-book.amir.cloud\"\u003edemo\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe Tomorrow Book, an experimental research project in form of an school assignment, is one of my early attempts to experiment with text driven design. Within this assignment, I studied various types of content containers in a digital environment and questioned the different reading experiences digital and analogue readers have to offer. As result, the Tomorrow Book was transferred onto a website where it claims that ‚Äúa new container requires new content‚Äù. This website uses Wikipedia articles in order to generate new reading narratives for books.\u003c/p\u003e\n","title":"Tomorrow Book","description":"\u003cp\u003eThe Tomorrow Book, an experimental research project in form of an school assignment, is one of my early attempts to experiment with text driven design. Within this assignment, I studied various types of content containers in a digital environment and questioned the different reading experiences digital and analogue readers have to offer. As result, the Tomorrow Book was transferred onto a website where it claims that ‚Äúa new container requires new content‚Äù. This website uses Wikipedia articles in order to generate new reading narratives for books.\u003c/p\u003e\n","tags":["research","website"],"slug":"tomorrow-book","thumb":{"src":"images/amir_houieh-Ry5DWjjTlFx1VTzoYTNki-320.png","srcSet":[{"path":"images/amir_houieh-Ry5DWjjTlFx1VTzoYTNki-320.png","size":320},{"path":"images/amir_houieh-Ry5DWjjTlFx1VTzoYTNki-640.png","size":640},{"path":"images/amir_houieh-Ry5DWjjTlFx1VTzoYTNki-1024.png","size":1024}],"caption":null,"alt":"Tomorrow Book-tomorrow-book.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-2aX19O_Lr1fn8yG_yz_KW-320.jpg","srcSet":[{"path":"images/amir_houieh-2aX19O_Lr1fn8yG_yz_KW-320.jpg","size":320},{"path":"images/amir_houieh-2aX19O_Lr1fn8yG_yz_KW-640.jpg","size":640},{"path":"images/amir_houieh-2aX19O_Lr1fn8yG_yz_KW-1024.jpg","size":1024}],"caption":null,"alt":"Tomorrow Book-1-image2.jpg","order":1,"r":1.5},{"src":"images/amir_houieh-VFroNQBQpOjPtguaH3oY8-320.jpg","srcSet":[{"path":"images/amir_houieh-VFroNQBQpOjPtguaH3oY8-320.jpg","size":320},{"path":"images/amir_houieh-VFroNQBQpOjPtguaH3oY8-640.jpg","size":640},{"path":"images/amir_houieh-VFroNQBQpOjPtguaH3oY8-1024.jpg","size":1024}],"caption":null,"alt":"Tomorrow Book-2-image3.jpg","order":2,"r":1.5},{"src":"images/amir_houieh-BNo1cwcY2LfNjDCUj1qT--320.jpg","srcSet":[{"path":"images/amir_houieh-BNo1cwcY2LfNjDCUj1qT--320.jpg","size":320},{"path":"images/amir_houieh-BNo1cwcY2LfNjDCUj1qT--640.jpg","size":640},{"path":"images/amir_houieh-BNo1cwcY2LfNjDCUj1qT--1024.jpg","size":1024}],"caption":null,"alt":"Tomorrow Book-3-image5.jpg","order":3,"r":1.5},{"src":"images/amir_houieh-0eWQOo7lYJ-hPIYBA7O7H-320.jpg","srcSet":[{"path":"images/amir_houieh-0eWQOo7lYJ-hPIYBA7O7H-320.jpg","size":320},{"path":"images/amir_houieh-0eWQOo7lYJ-hPIYBA7O7H-640.jpg","size":640},{"path":"images/amir_houieh-0eWQOo7lYJ-hPIYBA7O7H-1024.jpg","size":1024}],"caption":null,"alt":"Tomorrow Book-4-image1.jpg","order":4,"r":1.5},{"src":"images/amir_houieh-6RdsZYuH_RqLmS2RrjOI5-320.jpg","srcSet":[{"path":"images/amir_houieh-6RdsZYuH_RqLmS2RrjOI5-320.jpg","size":320},{"path":"images/amir_houieh-6RdsZYuH_RqLmS2RrjOI5-640.jpg","size":640},{"path":"images/amir_houieh-6RdsZYuH_RqLmS2RrjOI5-1024.jpg","size":1024}],"caption":null,"alt":"Tomorrow Book-5-image7.jpg","order":5,"r":1.5}],"stack":["js","html/css"],"dateString":"2015","dataYear":2015,"videos":[]},{"html":"\u003cp\u003eA Data driven spatial installation\nat \u003ca href=\"https://www.kabk.nl\"\u003e\u003ccode\u003eKABK\u003c/code\u003e\u003c/a\u003e, Den Haag\u003c/p\u003e\n\u003cp\u003eText and Space is a physical translation of the text. I created a system which uses the text as input. It extracts the required data from the text in order to create an space and spacial experiment for the viewers.\nEvery word becomes a dot in a three dimensional space and by connecting the dots a new space is evolved. This project is one of my first attempts working with text and data as material and shaping my visuals through systematic approach.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://amir.cloud/text_and_space\"\u003eSee Full Documentation\u003c/a\u003e\u003c/p\u003e\n","title":"Text \u0026 Space","description":"\u003cp\u003eText and Space is a physical translation of the text. I created a system which uses the text as input. It extracts the required data from the text in order to create an space and spacial experiment for the viewers.\nEvery word becomes a dot in a three dimensional space and by connecting the dots a new space is evolved. This project is one of my first attempts working with text and data as material and shaping my visuals through systematic approach.\u003c/p\u003e\n","tags":["data visualization","installation"],"slug":"text-and-space","thumb":{"src":"images/amir_houieh-7wQR-AlEABp3LDUlSnBTw-320.jpg","srcSet":[{"path":"images/amir_houieh-7wQR-AlEABp3LDUlSnBTw-320.jpg","size":320},{"path":"images/amir_houieh-7wQR-AlEABp3LDUlSnBTw-640.jpg","size":640},{"path":"images/amir_houieh-7wQR-AlEABp3LDUlSnBTw-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-mg_9988-2x.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-CTFIgjIK9iEh1M_qezKhh-320.jpg","srcSet":[{"path":"images/amir_houieh-CTFIgjIK9iEh1M_qezKhh-320.jpg","size":320},{"path":"images/amir_houieh-CTFIgjIK9iEh1M_qezKhh-640.jpg","size":640},{"path":"images/amir_houieh-CTFIgjIK9iEh1M_qezKhh-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-1-00-2x.jpg","order":1,"r":1.5},{"src":"images/amir_houieh-mMuPGzY7PuT8PMNpnNNW4-320.jpg","srcSet":[{"path":"images/amir_houieh-mMuPGzY7PuT8PMNpnNNW4-320.jpg","size":320},{"path":"images/amir_houieh-mMuPGzY7PuT8PMNpnNNW4-640.jpg","size":640},{"path":"images/amir_houieh-mMuPGzY7PuT8PMNpnNNW4-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-2-01-2x.jpg","order":2,"r":1.5},{"src":"images/amir_houieh--mAzMHtGiqS6Zli3mjnH3-320.jpg","srcSet":[{"path":"images/amir_houieh--mAzMHtGiqS6Zli3mjnH3-320.jpg","size":320},{"path":"images/amir_houieh--mAzMHtGiqS6Zli3mjnH3-640.jpg","size":640},{"path":"images/amir_houieh--mAzMHtGiqS6Zli3mjnH3-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-3-mg_0047-2x.jpg","order":3,"r":1.5},{"src":"images/amir_houieh--guoKOGzNPyRQv6PXn1jy-320.jpg","srcSet":[{"path":"images/amir_houieh--guoKOGzNPyRQv6PXn1jy-320.jpg","size":320},{"path":"images/amir_houieh--guoKOGzNPyRQv6PXn1jy-640.jpg","size":640},{"path":"images/amir_houieh--guoKOGzNPyRQv6PXn1jy-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-5-mg_0048-2x.jpg","order":5,"r":1.5},{"src":"images/amir_houieh-Ql1fABct4Fit-nCzcxLXu-320.jpg","srcSet":[{"path":"images/amir_houieh-Ql1fABct4Fit-nCzcxLXu-320.jpg","size":320},{"path":"images/amir_houieh-Ql1fABct4Fit-nCzcxLXu-640.jpg","size":640},{"path":"images/amir_houieh-Ql1fABct4Fit-nCzcxLXu-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-6-mg_0061-2x.jpg","order":6,"r":1.5},{"src":"images/amir_houieh-mDLbG4nwMKxtTs1yXY-my-320.jpg","srcSet":[{"path":"images/amir_houieh-mDLbG4nwMKxtTs1yXY-my-320.jpg","size":320},{"path":"images/amir_houieh-mDLbG4nwMKxtTs1yXY-my-640.jpg","size":640},{"path":"images/amir_houieh-mDLbG4nwMKxtTs1yXY-my-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-7-mg_9970-2x.jpg","order":7,"r":1.5},{"src":"images/amir_houieh-zvYHBe-CyS9If2pzUZ-uH-320.jpg","srcSet":[{"path":"images/amir_houieh-zvYHBe-CyS9If2pzUZ-uH-320.jpg","size":320},{"path":"images/amir_houieh-zvYHBe-CyS9If2pzUZ-uH-640.jpg","size":640},{"path":"images/amir_houieh-zvYHBe-CyS9If2pzUZ-uH-1024.jpg","size":1024}],"caption":null,"alt":"Text \u0026 Space-8-mg_9994-2x.jpg","order":8,"r":1.5}],"stack":null,"dateString":"2014","dataYear":2014,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://archive.amir.cloud/1_week_of_my_life_publication\"\u003earchive.amir.cloud/1_week_of_my_life_publication\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e1 week of my life is a series of artworks about one regular week of my life; one work for one day. This series could be consider as a irregular data-visualization representing the data.\nThe dataset was created by formulating my daily schedule into excel tables ‚Äîcategorizing my activities over the time(24hh). In order to make the data more humanized and so more flexible to make narratives, the third parameter was introduced: a parameter which represent my feeling regarding how slow or fast time is passed per activity category.\u003c/p\u003e\n\u003cp\u003eThis process results into 5 different dataset(s) (Monday to Friday) which are used as content/input for the artworks. You can see the all other related projects at \u003ca href=\"https://archive.amir.cloud\"\u003earchive.amir.cloud\u003c/a\u003e.\nThis publication is a generated visual book which is a documentation of these series. The book is design and programmed using html, css and javascript in web-browser.\u003c/p\u003e\n","title":"1 week of my life / publication","description":"\u003cp\u003e1 week of my life is a series of artworks about one regular week of my life; one work for one day. This series could be consider as a irregular data-visualization representing the data.\nThe dataset was created by formulating my daily schedule into excel tables ‚Äîcategorizing my activities over the time(24hh). In order to make the data more humanized and so more flexible to make narratives, the third parameter was introduced: a parameter which represent my feeling regarding how slow or fast time is passed per activity category.\u003c/p\u003e\n","tags":["generative book","alternative tool"],"slug":"1-week-of-my-life-publication","thumb":{"src":"images/amir_houieh-mbKEKbFWV1JN2jHhsjcdJ-320.jpg","srcSet":[{"path":"images/amir_houieh-mbKEKbFWV1JN2jHhsjcdJ-320.jpg","size":320},{"path":"images/amir_houieh-mbKEKbFWV1JN2jHhsjcdJ-640.jpg","size":640},{"path":"images/amir_houieh-mbKEKbFWV1JN2jHhsjcdJ-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-wednesdays13-2x.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-Xk_jE-frPtwkPgioCW83t-320.jpg","srcSet":[{"path":"images/amir_houieh-Xk_jE-frPtwkPgioCW83t-320.jpg","size":320},{"path":"images/amir_houieh-Xk_jE-frPtwkPgioCW83t-640.jpg","size":640},{"path":"images/amir_houieh-Xk_jE-frPtwkPgioCW83t-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-friday13-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559459gif___.gif","srcSet":[{"path":"images/amir_houieh-1761412559459gif___.gif","size":600}],"caption":"_.gif","alt":"_.gif","order":-1,"r":1.5},{"src":"images/amir_houieh-1761412559463gif____.gif","srcSet":[{"path":"images/amir_houieh-1761412559463gif____.gif","size":600}],"caption":"","alt":"1 week of my life / publication-gif____.gif","order":-1,"r":1.5},{"src":"images/amir_houieh-TSWzDeuyTVW0UP8Tfajdl-320.jpg","srcSet":[{"path":"images/amir_houieh-TSWzDeuyTVW0UP8Tfajdl-320.jpg","size":320},{"path":"images/amir_houieh-TSWzDeuyTVW0UP8Tfajdl-640.jpg","size":640},{"path":"images/amir_houieh-TSWzDeuyTVW0UP8Tfajdl-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-tuesdays13-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-YCsfT8MPiFfmkt9xEJgoY-320.jpg","srcSet":[{"path":"images/amir_houieh-YCsfT8MPiFfmkt9xEJgoY-320.jpg","size":320},{"path":"images/amir_houieh-YCsfT8MPiFfmkt9xEJgoY-640.jpg","size":640},{"path":"images/amir_houieh-YCsfT8MPiFfmkt9xEJgoY-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-wednesdays13-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-00aIRvbm6rwAamJhse6cq-320.jpg","srcSet":[{"path":"images/amir_houieh-00aIRvbm6rwAamJhse6cq-320.jpg","size":320},{"path":"images/amir_houieh-00aIRvbm6rwAamJhse6cq-640.jpg","size":640},{"path":"images/amir_houieh-00aIRvbm6rwAamJhse6cq-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-wednesdays2-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-2lMSwaBtPJhBJiuXncIQ7-320.jpg","srcSet":[{"path":"images/amir_houieh-2lMSwaBtPJhBJiuXncIQ7-320.jpg","size":320},{"path":"images/amir_houieh-2lMSwaBtPJhBJiuXncIQ7-640.jpg","size":640},{"path":"images/amir_houieh-2lMSwaBtPJhBJiuXncIQ7-1024.jpg","size":1024}],"caption":null,"alt":"1 week of my life / publication-wednesdays8-2x.jpg","order":-1,"r":1.5}],"stack":["js","html/css"],"dateString":"2013","dataYear":2013,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://archive.amir.cloud/2001_a_space_odyssey_round_1\"\u003e2001_a_space_odyssey_round_1\u003c/a\u003e\n\u003ca href=\"https://archive.amir.cloud/2001_a_space_odyssey_round_2\"\u003e2001_a_space_odyssey_round_2\u003c/a\u003e\n\u003ca href=\"https://archive.amir.cloud/2001_a_space_odyssey_round_3\"\u003e2001_a_space_odyssey_round_3\u003c/a\u003e\n\u003ca href=\"https://archive.amir.cloud/2001_a_space_odyssey_round_4\"\u003e2001_a_space_odyssey_round_4\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e2001 a space odyssey is a poster assignment ‚Äî by \u003ca href=\"http://carvalho-bernau.com\"\u003eSusana Carvalho\u003c/a\u003e ‚Äî consist of 4 phases/iteration. While the research phase the concepts such as construction and deconstruction and recursive loops came to my focus point. Furthermore I discovered about the technique used by film in order to create a sound in one of the famous sequences. They used a audio feedback loop where speaker outputs the sound which it creates.\nHence this concept lead me a to design a system in which I could create my poster with: a visual feedback loop. The setup consist of a typography layer of title of the movie (as the initial material/input) and a tv screen (to output the visuals) and a camera (to catch the visual input).\u003c/p\u003e\n","title":"2001 a space odyssey / poster series","description":"\u003cp\u003e2001 a space odyssey is a poster assignment ‚Äî by \u003ca href=\"http://carvalho-bernau.com\"\u003eSusana Carvalho\u003c/a\u003e ‚Äî consist of 4 phases/iteration. While the research phase the concepts such as construction and deconstruction and recursive loops came to my focus point. Furthermore I discovered about the technique used by film in order to create a sound in one of the famous sequences. They used a audio feedback loop where speaker outputs the sound which it creates.\nHence this concept lead me a to design a system in which I could create my poster with: a visual feedback loop. The setup consist of a typography layer of title of the movie (as the initial material/input) and a tv screen (to output the visuals) and a camera (to catch the visual input).\u003c/p\u003e\n","tags":["generative poster","alternative tool"],"slug":"2001-a-space-odyssey-poster-series","thumb":{"src":"images/amir_houieh-9NEWlJjNCck6y41eKI8tG-320.jpg","srcSet":[{"path":"images/amir_houieh-9NEWlJjNCck6y41eKI8tG-320.jpg","size":320},{"path":"images/amir_houieh-9NEWlJjNCck6y41eKI8tG-640.jpg","size":640},{"path":"images/amir_houieh-9NEWlJjNCck6y41eKI8tG-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6796_copy-2x.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-bLHSFkzV4PMdG3BIUy7Yn-320.jpg","srcSet":[{"path":"images/amir_houieh-bLHSFkzV4PMdG3BIUy7Yn-320.jpg","size":320},{"path":"images/amir_houieh-bLHSFkzV4PMdG3BIUy7Yn-640.jpg","size":640},{"path":"images/amir_houieh-bLHSFkzV4PMdG3BIUy7Yn-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6752_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-cee7fShOBsCYAgtiwI9Az-320.jpg","srcSet":[{"path":"images/amir_houieh-cee7fShOBsCYAgtiwI9Az-320.jpg","size":320},{"path":"images/amir_houieh-cee7fShOBsCYAgtiwI9Az-640.jpg","size":640},{"path":"images/amir_houieh-cee7fShOBsCYAgtiwI9Az-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6796_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-3nqNVHVqPLT3nmJmpi7SQ-320.jpg","srcSet":[{"path":"images/amir_houieh-3nqNVHVqPLT3nmJmpi7SQ-320.jpg","size":320},{"path":"images/amir_houieh-3nqNVHVqPLT3nmJmpi7SQ-640.jpg","size":640},{"path":"images/amir_houieh-3nqNVHVqPLT3nmJmpi7SQ-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6896_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-OHLOg_hYVdpvdfxkx0JLy-320.jpg","srcSet":[{"path":"images/amir_houieh-OHLOg_hYVdpvdfxkx0JLy-320.jpg","size":320},{"path":"images/amir_houieh-OHLOg_hYVdpvdfxkx0JLy-640.jpg","size":640},{"path":"images/amir_houieh-OHLOg_hYVdpvdfxkx0JLy-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6903_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-qkHQ0v8_F4s9tXR87pKH4-320.jpg","srcSet":[{"path":"images/amir_houieh-qkHQ0v8_F4s9tXR87pKH4-320.jpg","size":320},{"path":"images/amir_houieh-qkHQ0v8_F4s9tXR87pKH4-640.jpg","size":640},{"path":"images/amir_houieh-qkHQ0v8_F4s9tXR87pKH4-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_6940_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-VzBSAyxKnc52y5Wayee_b-320.jpg","srcSet":[{"path":"images/amir_houieh-VzBSAyxKnc52y5Wayee_b-320.jpg","size":320},{"path":"images/amir_houieh-VzBSAyxKnc52y5Wayee_b-640.jpg","size":640},{"path":"images/amir_houieh-VzBSAyxKnc52y5Wayee_b-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_7168_copy-2x.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh--BdjQpq2GNdLhA-0HOCRn-320.jpg","srcSet":[{"path":"images/amir_houieh--BdjQpq2GNdLhA-0HOCRn-320.jpg","size":320},{"path":"images/amir_houieh--BdjQpq2GNdLhA-0HOCRn-640.jpg","size":640},{"path":"images/amir_houieh--BdjQpq2GNdLhA-0HOCRn-1024.jpg","size":1024}],"caption":null,"alt":"2001 a space odyssey / poster series-_mg_7206-2x.jpg","order":-1,"r":1.5}],"stack":null,"dateString":"2013","dataYear":2013,"videos":[]},{"html":"\u003ch1\u003eNoui project\u003c/h1\u003e\n\u003cp\u003eNoui project is a series of experiments towards my vision and definition of the future of UI/UX design in software development; First, adaptability and organic personalization of interface design of software and second Automation and the design process. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExperiment #1\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe first experiment was a StyleGAN2 generated web grid, an attempt to see how we can teach a GAN to draw a random grid(layout) of a website. For this experiment, I used a dataset including the top 1000 websites with the most daily views. I am not quite happy with the results but now that the model is trained, it can be used for further (continue) training and hopefully get more coherent results. \u003c/p\u003e\n\u003cp\u003eIn order to create this dataset, I had to develop the software ‚á¢ \u003ca href=\"http://gridr.amir.cloud/\"\u003ehttp://gridr.amir.cloud/\u003c/a\u003e. The source code is open-source on Github ‚á¢ \u003ca href=\"https://github.com/amirhouieh/grid-reveal\"\u003ehttps://github.com/amirhouieh/grid-reveal\u003c/a\u003e. \u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eExperiment #2\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe second experiment was a WIREFRAME to UI generator using Pix2Pix GAN. In this step, I used a dataset including 1000 random data points (webpages). The result did not look good, but promising ü§û¬†The next step would be to create a more cohesive and clean dataset (probably limited to one particular domain), and train the model again. \u003c/p\u003e\n\u003cp\u003eLink to Colab project ‚á¢ \u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\"\u003eGoogle Colaboratory\u003c/a\u003e\u003c/p\u003e\n","title":"noui","description":"\u003cp\u003eThe first experiment was a StyleGAN2 generated web grid, an attempt to see how we can teach a GAN to draw a random grid(layout) of a website. For this experiment, I used a dataset including the top 1000 websites with the most daily views. I am not quite happy with the results but now that the model is trained, it can be used for further (continue) training and hopefully get more coherent results. \u003c/p\u003e\n","blurb":"Machine learning experiments exploring the future of UI/UX design using StyleGAN2 and Pix2Pix for automated interface generation.","tags":["Experiment","Machine Learning"],"slug":"noui","thumb":{"src":"images/amir_houieh-1761412559399ezgif-2-d790860933.gif","srcSet":[{"path":"images/amir_houieh-1761412559399ezgif-2-d790860933.gif","size":600}],"caption":null,"alt":"noui-ezgif-2-d790860933.gif","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-1761412559448ezgif-2-a57c9da08d.gif","srcSet":[{"path":"images/amir_houieh-1761412559448ezgif-2-a57c9da08d.gif","size":600}],"caption":null,"alt":"noui-ezgif-2-a57c9da08d.gif","order":-1,"r":1.5}],"stack":["StyleGan2","Pix2Pix","Python"],"dateString":"2020","dataYear":2020,"videos":[],"order":1322},{"html":"\u003cp\u003e\u003ca href=\"https://projectindefensible.org\"\u003eprojectindefensible.org\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://lust.nl\"\u003e\u003ccode\u003eLUST/LUSTLAB\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://eric.young.li\"\u003e\u003ccode\u003eEric Li\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://linkedin.com/in/lenarobin\"\u003e\u003ccode\u003eL√©na Robin\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eProject Indefensible emerged out of a series of research and discussion workshops on the global arms business. The result of this collaboration is the educational website and text of Indefensible. In order to stimulate this conversation, \u003ca href=\"https://lust.nl\"\u003eLUST\u003c/a\u003e, where I worked as a designer and developer, approached the design and implementation of the website as a critical tool for collaborative reading and writing. LUST offered speculations on scalable reading experiences between all target audiences, situations, and locations centered on the thematics of the Indefensible text.\nMy contribution to this project was mainly implementation and software development including both back-end and front-end. As a result, the website for Indefensible offers the reader a set of tools which you can find at the online website.\u003c/p\u003e\n","title":"Project Indefensible","description":"\u003cp\u003eProject Indefensible emerged out of a series of research and discussion workshops on the global arms business. The result of this collaboration is the educational website and text of Indefensible. In order to stimulate this conversation, \u003ca href=\"https://lust.nl\"\u003eLUST\u003c/a\u003e, where I worked as a designer and developer, approached the design and implementation of the website as a critical tool for collaborative reading and writing. LUST offered speculations on scalable reading experiences between all target audiences, situations, and locations centered on the thematics of the Indefensible text.\nMy contribution to this project was mainly implementation and software development including both back-end and front-end. As a result, the website for Indefensible offers the reader a set of tools which you can find at the online website.\u003c/p\u003e\n","tags":["website","publishing platform"],"slug":"project-indefensible","thumb":{"src":"images/amir_houieh-d5pzs9nrNTLrntOryvuBy-320.jpg","srcSet":[{"path":"images/amir_houieh-d5pzs9nrNTLrntOryvuBy-320.jpg","size":320},{"path":"images/amir_houieh-d5pzs9nrNTLrntOryvuBy-640.jpg","size":640},{"path":"images/amir_houieh-d5pzs9nrNTLrntOryvuBy-1024.jpg","size":1024}],"caption":null,"alt":"Project Indefensible-indefensible.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-I92MncpPHk5KLFntFZTqO-320.png","srcSet":[{"path":"images/amir_houieh-I92MncpPHk5KLFntFZTqO-320.png","size":320},{"path":"images/amir_houieh-I92MncpPHk5KLFntFZTqO-640.png","size":640},{"path":"images/amir_houieh-I92MncpPHk5KLFntFZTqO-1024.png","size":1024}],"caption":"highlighting and note taking","alt":"highlighting and note taking","order":-1,"r":1.5},{"src":"images/amir_houieh-KbHbW-vac02FwQgTI0eOR-320.png","srcSet":[{"path":"images/amir_houieh-KbHbW-vac02FwQgTI0eOR-320.png","size":320},{"path":"images/amir_houieh-KbHbW-vac02FwQgTI0eOR-640.png","size":640},{"path":"images/amir_houieh-KbHbW-vac02FwQgTI0eOR-1024.png","size":1024}],"caption":"search","alt":"search","order":-1,"r":1.5}],"stack":["js","html/css"],"dateString":"2016","dataYear":2016,"videos":[],"order":999},{"html":"\u003cp\u003e\u003ca href=\"https://isiaurbino.net\"\u003eisiaurbino.net\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"http://zerodotzero.net\"\u003e\u003ccode\u003eZero Dot Zero\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe project is a result of about 6 months of dedicated collaboration with Zero Dot Zero as a continuation to  our previous project in the field of #experimentalpublishing and #digitalpublishing.\nThis platform uses Google Drive and Google Calendar as CMS; users produce, edit and upload their content using GDoc, GSpreadsheets, GCal and/or any other file formats in Gdrive, whereupon the software processes and exposes the content publicly via two APIs #Restful \u0026amp; #GraphQl).\u003c/p\u003e\n\u003cp\u003eAccreditation:\u003c/p\u003e\n\u003cp\u003eISIA Urbino Identity:\nZeroDotZero\u003c/p\u003e\n\u003cp\u003eSoftware Architecture \u0026amp; Development:\nAmir Houieh\u003c/p\u003e\n\u003cp\u003eConcept \u0026amp; Design:\nMaaike Besseling, Thomas Castro, Michiel Terpelle\u003c/p\u003e\n\u003cp\u003eIdentity Implementation:\nMaloe Brinkman, Thomas Castro, Jurrit van der Ploeg\u003c/p\u003e\n\u003cp\u003eCoordination:\nWietske Flederus, Floor Weijs\u003c/p\u003e\n","title":"ISIA Urbino Digital Platform","description":"\u003cp\u003eThe project is a result of about 6 months of dedicated collaboration with Zero Dot Zero as a continuation to  our previous project in the field of #experimentalpublishing and #digitalpublishing.\nThis platform uses Google Drive and Google Calendar as CMS; users produce, edit and upload their content using GDoc, GSpreadsheets, GCal and/or any other file formats in Gdrive, whereupon the software processes and exposes the content publicly via two APIs #Restful \u0026amp; #GraphQl).\u003c/p\u003e\n","tags":["website","publishing platform"],"slug":"isia-urbino-digital-platform","thumb":{"src":"images/amir_houieh-8M5tPmSStFju08SRVzo71-320.jpg","srcSet":[{"path":"images/amir_houieh-8M5tPmSStFju08SRVzo71-320.jpg","size":320},{"path":"images/amir_houieh-8M5tPmSStFju08SRVzo71-640.jpg","size":640},{"path":"images/amir_houieh-8M5tPmSStFju08SRVzo71-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-2.jpg","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-hZRHNu1iSaaIsm_qgdEs8-320.jpg","srcSet":[{"path":"images/amir_houieh-hZRHNu1iSaaIsm_qgdEs8-320.jpg","size":320},{"path":"images/amir_houieh-hZRHNu1iSaaIsm_qgdEs8-640.jpg","size":640},{"path":"images/amir_houieh-hZRHNu1iSaaIsm_qgdEs8-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-3.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-TpxDNeeg_RaXlHh0lMLf6-320.jpg","srcSet":[{"path":"images/amir_houieh-TpxDNeeg_RaXlHh0lMLf6-320.jpg","size":320},{"path":"images/amir_houieh-TpxDNeeg_RaXlHh0lMLf6-640.jpg","size":640},{"path":"images/amir_houieh-TpxDNeeg_RaXlHh0lMLf6-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-4.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-G1mjSpo7XfyQtiFFllHn0-320.jpg","srcSet":[{"path":"images/amir_houieh-G1mjSpo7XfyQtiFFllHn0-320.jpg","size":320},{"path":"images/amir_houieh-G1mjSpo7XfyQtiFFllHn0-640.jpg","size":640},{"path":"images/amir_houieh-G1mjSpo7XfyQtiFFllHn0-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-5.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-eBdjoGDkd2ANc8Kh6CAZS-320.jpg","srcSet":[{"path":"images/amir_houieh-eBdjoGDkd2ANc8Kh6CAZS-320.jpg","size":320},{"path":"images/amir_houieh-eBdjoGDkd2ANc8Kh6CAZS-640.jpg","size":640},{"path":"images/amir_houieh-eBdjoGDkd2ANc8Kh6CAZS-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-6.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-BEQNXMJtyfjPxz2Ec8W95-320.jpg","srcSet":[{"path":"images/amir_houieh-BEQNXMJtyfjPxz2Ec8W95-320.jpg","size":320},{"path":"images/amir_houieh-BEQNXMJtyfjPxz2Ec8W95-640.jpg","size":640},{"path":"images/amir_houieh-BEQNXMJtyfjPxz2Ec8W95-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-7.jpg","order":-1,"r":1.5},{"src":"images/amir_houieh-BdZDX2JcGLH1929tEvTHK-320.jpg","srcSet":[{"path":"images/amir_houieh-BdZDX2JcGLH1929tEvTHK-320.jpg","size":320},{"path":"images/amir_houieh-BdZDX2JcGLH1929tEvTHK-640.jpg","size":640},{"path":"images/amir_houieh-BdZDX2JcGLH1929tEvTHK-1024.jpg","size":1024}],"caption":null,"alt":"ISIA Urbino Digital Platform-render-8.jpg","order":-1,"r":1.5}],"stack":["React","html/css","Typescript","Nodejs","GraphQl","Google API"],"dateString":"2020","dataYear":2020,"videos":[],"order":888},{"html":"\u003cp\u003e\u003ca href=\"https://25thhour.rndr.studio\"\u003e25thhour\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis is one of the projects which I worked on at RNDR.\u003c/p\u003e\n\u003cp\u003e25th Hour: Flow is a project by Audi in partnership with the Karlsruhe Institute for Technology (KIT), MobilityPartners and \u003ca href=\"https://rndr.studio\"\u003eRNDR\u003c/a\u003e. Based on data obtained from a simulation conducted by KIT and MobilityPartners, 25th Hour visualizes the potential impact of autonomous cars, ride sharing and smart traffic management on the traffic of Ingolstadt, Germany.\u003c/p\u003e\n","title":"The 25th Hour","description":"\u003cp\u003e25th Hour: Flow is a project by Audi in partnership with the Karlsruhe Institute for Technology (KIT), MobilityPartners and \u003ca href=\"https://rndr.studio\"\u003eRNDR\u003c/a\u003e. Based on data obtained from a simulation conducted by KIT and MobilityPartners, 25th Hour visualizes the potential impact of autonomous cars, ride sharing and smart traffic management on the traffic of Ingolstadt, Germany.\u003c/p\u003e\n","tags":["data visualization","webGl","map visualization"],"slug":"the-25th-hour","thumb":{"src":"images/amir_houieh-fIB7UR8mYPCfs0_dSdllz-320.png","srcSet":[{"path":"images/amir_houieh-fIB7UR8mYPCfs0_dSdllz-320.png","size":320},{"path":"images/amir_houieh-fIB7UR8mYPCfs0_dSdllz-640.png","size":640},{"path":"images/amir_houieh-fIB7UR8mYPCfs0_dSdllz-1024.png","size":1024}],"caption":null,"alt":"The 25th Hour-Screen Shot 2019-03-12 at 16.05.08.png","order":-1,"r":1.5},"images":[],"stack":["js","html/css","TypeScript","React","Mapbox","Kotlin","OPENRNDR"],"dateString":"2018","dataYear":2018,"videos":[{"src":"https://vimeo.com/311687534","source":"vimeo","caption":null,"order":2}],"order":777},{"html":"\u003cp\u003e\u003cem\u003eA modular content-driven web browser\u003c/em\u003e\n\u003ca href=\"https://github.com/amirhouieh/re-\"\u003esource code on Github\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eRe is my graduation project, which already contains some of the key ideas of the Repub project. Re is a new web browser, altering the way we surf and consume on the web. Re empowers the user to embrace the content of the web pages as well as the design, empowering them to reflect on the way content is shown. Re is a modular platform within which users can decide what type of content they want to see on a webpage\nThis is enabled by creating and adding content modules to the browser. Therefore, Re becomes a super minimal browser which is faster, more reliable, and more efficient in terms of data-consumption by cutting off all the noises from a webpage‚Äôs content.\u003c/p\u003e\n","title":"Re-","description":"\u003cp\u003eRe is my graduation project, which already contains some of the key ideas of the Repub project. Re is a new web browser, altering the way we surf and consume on the web. Re empowers the user to embrace the content of the web pages as well as the design, empowering them to reflect on the way content is shown. Re is a modular platform within which users can decide what type of content they want to see on a webpage\nThis is enabled by creating and adding content modules to the browser. Therefore, Re becomes a super minimal browser which is faster, more reliable, and more efficient in terms of data-consumption by cutting off all the noises from a webpage‚Äôs content.\u003c/p\u003e\n","blurb":"Modular web browser that empowers users to customize content consumption and cut through webpage noise with content modules.","tags":["experimental publishing","software","DIY tool"],"slug":"re","thumb":{"src":"images/amir_houieh-IsJ8LWLrKPvx-80mmAz4F-320.png","srcSet":[{"path":"images/amir_houieh-IsJ8LWLrKPvx-80mmAz4F-320.png","size":320},{"path":"images/amir_houieh-IsJ8LWLrKPvx-80mmAz4F-640.png","size":640},{"path":"images/amir_houieh-IsJ8LWLrKPvx-80mmAz4F-1024.png","size":1024}],"caption":null,"alt":"Re--re-browser-homepage.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-H6D-nfKMTJPy2dVyqRIMl-320.png","srcSet":[{"path":"images/amir_houieh-H6D-nfKMTJPy2dVyqRIMl-320.png","size":320},{"path":"images/amir_houieh-H6D-nfKMTJPy2dVyqRIMl-640.png","size":640},{"path":"images/amir_houieh-H6D-nfKMTJPy2dVyqRIMl-1024.png","size":1024}],"caption":"How a Wikipedia page could look like in Re","alt":"How a Wikipedia page could look like in Re","order":1,"r":1.5},{"src":"images/amir_houieh-rq81NiDxyNTWxcA7w52qt-320.png","srcSet":[{"path":"images/amir_houieh-rq81NiDxyNTWxcA7w52qt-320.png","size":320},{"path":"images/amir_houieh-rq81NiDxyNTWxcA7w52qt-640.png","size":640},{"path":"images/amir_houieh-rq81NiDxyNTWxcA7w52qt-1024.png","size":1024}],"caption":"How Google search could look like in Re","alt":"How Google search could look like in Re","order":2,"r":1.5},{"src":"images/amir_houieh-L1gZKz1xhhhtBPFj6rcfs-320.png","srcSet":[{"path":"images/amir_houieh-L1gZKz1xhhhtBPFj6rcfs-320.png","size":320},{"path":"images/amir_houieh-L1gZKz1xhhhtBPFj6rcfs-640.png","size":640},{"path":"images/amir_houieh-L1gZKz1xhhhtBPFj6rcfs-1024.png","size":1024}],"caption":"How KABK.nl could look like in Re","alt":"How KABK.nl could look like in Re","order":3,"r":1.5},{"src":"images/amir_houieh-gvfl9m4CglGBVP1EhBy9Y-320.png","srcSet":[{"path":"images/amir_houieh-gvfl9m4CglGBVP1EhBy9Y-320.png","size":320},{"path":"images/amir_houieh-gvfl9m4CglGBVP1EhBy9Y-640.png","size":640},{"path":"images/amir_houieh-gvfl9m4CglGBVP1EhBy9Y-1024.png","size":1024}],"caption":"General UI of Re - menu","alt":"General UI of Re - menu","order":4,"r":1.5},{"src":"images/amir_houieh-DaUUSVrUuZqrOlDGLcmBX-320.png","srcSet":[{"path":"images/amir_houieh-DaUUSVrUuZqrOlDGLcmBX-320.png","size":320},{"path":"images/amir_houieh-DaUUSVrUuZqrOlDGLcmBX-640.png","size":640},{"path":"images/amir_houieh-DaUUSVrUuZqrOlDGLcmBX-1024.png","size":1024}],"caption":"General UI of Re - browser history","alt":"General UI of Re - browser history","order":5,"r":1.5},{"src":"images/amir_houieh-dZfKYPtBCvEgA9TbV1C26-320.png","srcSet":[{"path":"images/amir_houieh-dZfKYPtBCvEgA9TbV1C26-320.png","size":320},{"path":"images/amir_houieh-dZfKYPtBCvEgA9TbV1C26-640.png","size":640},{"path":"images/amir_houieh-dZfKYPtBCvEgA9TbV1C26-1024.png","size":1024}],"caption":"General UI of Re - shortcuts","alt":"General UI of Re - shortcuts","order":6,"r":1.5}],"stack":["js","html/css","electron-js"],"dateString":"2016","dataYear":2016,"videos":[],"order":669},{"html":"\u003cp\u003e\u003ca href=\"https://pagesmagazine.net\"\u003epagesmagazine.net\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://lust.nl\"\u003e\u003ccode\u003eLUST/LUSTLAB\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://linkedin.com/in/lenarobin\"\u003e\u003ccode\u003eL√©na Robin\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://krks.info/\"\u003e\u003ccode\u003eGabor Kerekes\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThis project is the online expansion of the publishing work of Pages, the bilingual, Farsi and English, artist magazine. This platform operates primarily as a working space, concerned with rethinking the politics and practice of archiving and publishing. It approaches publishing as a collective practice of generating an open, transparent archive. With minimum editorial mediation, the platform offers direct access to invited authors to publish their contributions, while making them instantly accessible to the reader. The central tool facilitating this is the automated mailing system which authors use to upload, edit, and expand on their contributions.\nI was proudly involved in the research, design, and implementation phase of this project during my time at LUST/LustLab. I can honestly say that the Pages project was my best working experience during this time for two reasons: Firstly, because the project was about online publishing, a topic of special interest to me and secondly, because of my major position within the project which brought me a lot of responsibilities as well as challenges.\u003c/p\u003e\n","title":"Pages","description":"\u003cp\u003eThis project is the online expansion of the publishing work of Pages, the bilingual, Farsi and English, artist magazine. This platform operates primarily as a working space, concerned with rethinking the politics and practice of archiving and publishing. It approaches publishing as a collective practice of generating an open, transparent archive. With minimum editorial mediation, the platform offers direct access to invited authors to publish their contributions, while making them instantly accessible to the reader. The central tool facilitating this is the automated mailing system which authors use to upload, edit, and expand on their contributions.\nI was proudly involved in the research, design, and implementation phase of this project during my time at LUST/LustLab. I can honestly say that the Pages project was my best working experience during this time for two reasons: Firstly, because the project was about online publishing, a topic of special interest to me and secondly, because of my major position within the project which brought me a lot of responsibilities as well as challenges.\u003c/p\u003e\n","blurb":"Bilingual publishing platform for collaborative archiving with automated mailing system and direct author access.","tags":["website","publishing platform"],"slug":"pages","thumb":{"src":"images/amir_houieh-mMeRvJdUd9wcBY8tK1OVK-320.png","srcSet":[{"path":"images/amir_houieh-mMeRvJdUd9wcBY8tK1OVK-320.png","size":320},{"path":"images/amir_houieh-mMeRvJdUd9wcBY8tK1OVK-640.png","size":640},{"path":"images/amir_houieh-mMeRvJdUd9wcBY8tK1OVK-1024.png","size":1024}],"caption":null,"alt":"Pages-pagesmagazine.net.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-EK46O6PFfZfKscbXDx3TZ-320.png","srcSet":[{"path":"images/amir_houieh-EK46O6PFfZfKscbXDx3TZ-320.png","size":320},{"path":"images/amir_houieh-EK46O6PFfZfKscbXDx3TZ-640.png","size":640},{"path":"images/amir_houieh-EK46O6PFfZfKscbXDx3TZ-1024.png","size":1024}],"caption":"Pages platform has it‚Äôs own search engine, which enables the users to search among different type of content within its database","alt":"Pages platform has it‚Äôs own search engine, which enables the users to search among different type of content within its database","order":1,"r":1.5},{"src":"images/amir_houieh-s7lx7-_xXdC1GW4MSqXJ2-320.png","srcSet":[{"path":"images/amir_houieh-s7lx7-_xXdC1GW4MSqXJ2-320.png","size":320},{"path":"images/amir_houieh-s7lx7-_xXdC1GW4MSqXJ2-640.png","size":640},{"path":"images/amir_houieh-s7lx7-_xXdC1GW4MSqXJ2-1024.png","size":1024}],"caption":"Versioning for articles and other types of content","alt":"Versioning for articles and other types of content","order":2,"r":1.5},{"src":"images/amir_houieh-ZtX9bs3aBrqoTwzOSuIhd-320.png","srcSet":[{"path":"images/amir_houieh-ZtX9bs3aBrqoTwzOSuIhd-320.png","size":320},{"path":"images/amir_houieh-ZtX9bs3aBrqoTwzOSuIhd-640.png","size":640},{"path":"images/amir_houieh-ZtX9bs3aBrqoTwzOSuIhd-1024.png","size":1024}],"caption":"Users are able to create their own magazines  by adding:removing articles to their collection. Further the platform enables them to publish their collection with other users and:or generate a designed PDF version","alt":"Users are able to create their own magazines  by adding:removing articles to their collection. Further the platform enables them to publish their collection with other users and:or generate a designed PDF version","order":3,"r":1.5},{"src":"images/amir_houieh-9bSLPgxOgeiCExywDHxvY-320.png","srcSet":[{"path":"images/amir_houieh-9bSLPgxOgeiCExywDHxvY-320.png","size":320},{"path":"images/amir_houieh-9bSLPgxOgeiCExywDHxvY-640.png","size":640},{"path":"images/amir_houieh-9bSLPgxOgeiCExywDHxvY-1024.png","size":1024}],"caption":null,"alt":"Pages-4-Screen Shot 2018-09-30 at 22.22.51.png","order":4,"r":1.5},{"src":"images/amir_houieh-gMRSyZiStMTG1Lpyo7cg_-320.png","srcSet":[{"path":"images/amir_houieh-gMRSyZiStMTG1Lpyo7cg_-320.png","size":320},{"path":"images/amir_houieh-gMRSyZiStMTG1Lpyo7cg_-640.png","size":640},{"path":"images/amir_houieh-gMRSyZiStMTG1Lpyo7cg_-1024.png","size":1024}],"caption":null,"alt":"Pages-5-Screen Shot 2018-09-30 at 22.23.16.png","order":5,"r":1.5},{"src":"images/amir_houieh-yQv8_DZ8rQEcimNr1IHk_-320.png","srcSet":[{"path":"images/amir_houieh-yQv8_DZ8rQEcimNr1IHk_-320.png","size":320},{"path":"images/amir_houieh-yQv8_DZ8rQEcimNr1IHk_-640.png","size":640},{"path":"images/amir_houieh-yQv8_DZ8rQEcimNr1IHk_-1024.png","size":1024}],"caption":null,"alt":"Pages-6-Screen Shot 2018-09-30 at 22.23.24.png","order":6,"r":1.5}],"stack":["es6","html/css","React","Nodejs","docker","monogo-DB","express-js","smtp-server"],"dateString":"2016-2017","dataYear":2017,"videos":[],"order":666}],"currentProjects":[{"html":"\u003cp\u003eHiro is a market place for generative and interactive artworks.\u003c/p\u003e\n","link":"https://hir.ooo","title":"HIRO","description":"\u003cp\u003eHiro is a market place for generative and interactive artworks.\u003c/p\u003e\n","tags":["SAAS","Online platform","Creative coding"],"current":true,"slug":"hiro","thumb":{"src":"images/amir_houieh-xwd_T8_124myXWlS9o4sL-320.png","srcSet":[{"path":"images/amir_houieh-xwd_T8_124myXWlS9o4sL-320.png","size":320},{"path":"images/amir_houieh-xwd_T8_124myXWlS9o4sL-640.png","size":640},{"path":"images/amir_houieh-xwd_T8_124myXWlS9o4sL-1024.png","size":1024}],"caption":null,"alt":"HIRO-logox.png","order":-1,"r":1.5},"images":[],"stack":null,"dateString":"2021","dataYear":2021,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://suslib.com\"\u003eSUSLIB\u003c/a\u003e aims to build the future of knowledge interaction combining computational design, research and A.I. \u003c/p\u003e\n","link":"https://suslib.com","title":"SUSLIB","description":"\u003cp\u003e\u003ca href=\"https://suslib.com\"\u003eSUSLIB\u003c/a\u003e aims to build the future of knowledge interaction combining computational design, research and A.I. \u003c/p\u003e\n","tags":["A.I. software","digital/physical interactions","SAAS","Machine learning","Future of knowledge"],"current":true,"slug":"suslib","thumb":{"src":"images/amir_houieh-iqYNSyZlxobC9NfOM4Ozy-320.jpg","srcSet":[{"path":"images/amir_houieh-iqYNSyZlxobC9NfOM4Ozy-320.jpg","size":320},{"path":"images/amir_houieh-iqYNSyZlxobC9NfOM4Ozy-640.jpg","size":640},{"path":"images/amir_houieh-iqYNSyZlxobC9NfOM4Ozy-1024.jpg","size":1024}],"caption":null,"alt":"SUSLIB-1617215097-index-cover-autonomous-library-centered-light.jpg","order":1,"r":1.5},"images":[],"stack":null,"dateString":"2018","dataYear":2018,"videos":[]},{"html":"\u003cp\u003e\u003ca href=\"https://unbody.io\"\u003eUnbody\u003c/a\u003e is a damn easy API for advanced AI, from chatbots to generative search, for your private data‚Äîwhether it\u0026#39;s on Google Drive or Slack, in any format from PDFs to spreadsheets to videos‚Äîall via a single GraphQl touchpoint.\u003c/p\u003e\n","link":"https://unbody.io","title":"Unbody","description":"\u003cp\u003e\u003ca href=\"https://unbody.io\"\u003eUnbody\u003c/a\u003e is a damn easy API for advanced AI, from chatbots to generative search, for your private data‚Äîwhether it\u0026#39;s on Google Drive or Slack, in any format from PDFs to spreadsheets to videos‚Äîall via a single GraphQl touchpoint.\u003c/p\u003e\n","tags":["A.I. software","SAAS","Machine learning","LLM"],"current":true,"slug":"unbody","thumb":{"src":"images/amir_houieh-K1GfOHGQjpkdMx1dW-Lg4-320.jpg","srcSet":[{"path":"images/amir_houieh-K1GfOHGQjpkdMx1dW-Lg4-320.jpg","size":320},{"path":"images/amir_houieh-K1GfOHGQjpkdMx1dW-Lg4-640.jpg","size":640},{"path":"images/amir_houieh-K1GfOHGQjpkdMx1dW-Lg4-1024.jpg","size":1024}],"caption":null,"alt":"Unbody-Frame 25.jpg","order":-1,"r":1.5},"images":[],"stack":null,"dateString":"2018","dataYear":2018,"videos":[]}]},"__N_SSG":true},"page":"/","query":{},"buildId":"aqAUvMRKsTzW4luGvoG2f","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>