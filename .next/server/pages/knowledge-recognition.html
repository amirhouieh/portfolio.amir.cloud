<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>Knowledge Recognition by Amir Houieh</title><meta name="keywords" content="amir houieh, amirhouieh"/><meta name="description" content="This was 2018, so we didn&#x27;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word..."/><meta name="copyright" content="amir.cloud"/><meta name="language" content="EN"/><meta name="Classification" content="Design/Programming"/><meta name="author" content="Amir, amir.houieh@gmail.com"/><meta name="designer" content="amir houieh"/><meta name="owner" content="amir houieh"/><meta name="url" content="https://portfolio.amir.cloud/knowledge-recognition"/><meta name="identifier-URL" content="https://portfolio.amir.cloud/knowledge-recognition"/><meta property="og:title" content="Knowledge Recognition by Amir Houieh"/><meta property="og:url" content="https://portfolio.amir.cloud/knowledge-recognition"/><meta property="og:image" content="https://portfolio.amir.cloud/images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png"/><meta property="og:site_name" content="amir houieh"/><meta property="og:type" content="website"/><meta property="og:description" content="This was 2018, so we didn&#x27;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word..."/><meta name="twitter:image" content="https://portfolio.amir.cloud/images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png"/><meta itemProp="name" content="https://portfolio.amir.cloud/knowledge-recognition"/><meta itemProp="description" content="This was 2018, so we didn&#x27;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word..."/><meta itemProp="image" content="https://portfolio.amir.cloud/images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png"/><script type="application/ld+json">
              {
                &quot;@context&quot;: &quot;https://json-ld.org/contexts/person.jsonld&quot;,
                &quot;name&quot;: &quot;Amir Houieh&quot;,
                &quot;born&quot;: &quot;1987-03-22&quot;,
                &quot;url&quot;: &quot;amir.houieh&quot;,
                &quot;contactPoint&quot;: {
                  &quot;@type&quot;: &quot;ContactPoint&quot;,
                  &quot;availableLanguage&quot;: [&quot;English&quot;]
                },
                  &quot;sameAs&quot;: [
                  &quot;https://www.linkedin.com/in/amirhouieh&quot;,
                  &quot;https://github.com/amirhouieh&quot;,
                  &quot;https://vimeo.com/user13046302&quot;,
                  &quot;https://twitter.com/amirhouieh&quot;
                ]
              }
        </script><meta name="next-head-count" content="24"/><link rel="preload" href="/_next/static/css/89f6c9f565961e37.css" as="style"/><link rel="stylesheet" href="/_next/static/css/89f6c9f565961e37.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-42372ed130431b0a.js"></script><script src="/_next/static/chunks/webpack-96470c7b0317e27e.js" defer=""></script><script src="/_next/static/chunks/framework-64ad27b21261a9ce.js" defer=""></script><script src="/_next/static/chunks/main-a16c617c42bd88d0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-3e399e5cc9feb1c1.js" defer=""></script><script src="/_next/static/chunks/63-071348b73b9c6dd3.js" defer=""></script><script src="/_next/static/chunks/984-a8b69ab87f1229c4.js" defer=""></script><script src="/_next/static/chunks/4-0cf1ea086bbc82f7.js" defer=""></script><script src="/_next/static/chunks/pages/%5Bslug%5D-25e06b2eebb16a85.js" defer=""></script><script src="/_next/static/aqAUvMRKsTzW4luGvoG2f/_buildManifest.js" defer=""></script><script src="/_next/static/aqAUvMRKsTzW4luGvoG2f/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><div class="blur" font-size="36" style="text-shadow:0 0 50px blue;color:transparent;display:inline-block"><a href="/"><h2 class="page-info">/</h2></a><a title="about me" href="https://amir.cloud"><small>amir houieh</small></a></div><br/><br/><br/><div class="project container"><div><div class="page-header"><a style="display:none" href="/knowledge-recognition/"></a><code class="date">2018</code><h2 class="page-info">Knowledge Recognition</h2><div class="tags"><i>AI</i>, <i>semantic-search</i>, <i>ML</i>, <i>knowledge systems</i></div><div class="stack"><span>YOLOv3</span><span>, </span><span>Mask R-CNN</span><span>, </span><span>Tesseract OCR</span><span>, </span><span>spaCy</span><span>, </span><span>LDA</span><span>, </span><span>Word2Vec</span><span>, </span><span>Elasticsearch</span><span>, </span><span>TensorFlow</span><span>, </span><span>PyTorch</span><span>, </span><span>REST API</span><span>, </span><span>Streaming API</span></div><a href="https://suslib.com/core/knowledge-recognition" target="_blank" class="external-link">https://suslib.com/core/knowledge-recognition</a></div><div class="page-hero"><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-knowledge-recognition.png"><img src="../images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png" alt="amir houieh - Knowledge Recognition-knowledge-recognition.png" title="amir houieh - Knowledge Recognition-knowledge-recognition.png" srcSet="../images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png 320w, ../images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-640.png 640w, ../images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png 1024w"/></a></figure></div><div class="page-info"><p>KR was our first big experiment at <a href="https://suslib.com">Suslib</a>. The idea was simple: what if a collection of books, images, or files could actually understand itself? Instead of being a flat archive, it would be a network of meaning that you could search semantically and explore contextually.</p>
<p>This was 2018, so we didn&#39;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word2Vec embeddings and dropped them into Elasticsearch to give collections a &quot;search by idea&quot; capability. It felt like hacking the future together with duct tape and GPUs.</p>
<p>I led the team that built it — backend, ML, and MLOps engineers — and my role was to drive the product architecture, glue all the moving parts, and also get my hands dirty with model training and pipeline design. We wrapped it all into a REST and streaming API that sat neatly between a CMS and database. That made it lightweight, flexible, and fast enough to power our own AR inventory app while still being useful for outside developers.</p>
<p>Looking back, KR was the project that put us on the map: it got us into Dutch Design Week, helped us secure funding, and proved that we could build practical AI-driven knowledge systems before the ecosystem was ready for it.</p>
<p><code>with</code> <a href="https://suslib.com">Martijn de Heer</a>, <a href="https://suslib.com">Homayoun Moradi</a></p>
</div></div><div class="page-images"><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-image1.png"><img src="../images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png" alt="amir houieh - Knowledge Recognition-image1.png" title="amir houieh - Knowledge Recognition-image1.png" srcSet="../images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png 320w, ../images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-640.png 640w, ../images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-1024.png 1024w"/></a></figure><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-image2.png"><img src="../images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png" alt="amir houieh - Knowledge Recognition-image2.png" title="amir houieh - Knowledge Recognition-image2.png" srcSet="../images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png 320w, ../images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-640.png 640w, ../images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-1024.png 1024w"/></a></figure><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-image3.png"><img src="../images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png" alt="amir houieh - Knowledge Recognition-image3.png" title="amir houieh - Knowledge Recognition-image3.png" srcSet="../images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png 320w, ../images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-640.png 640w, ../images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-1024.png 1024w"/></a></figure><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-image4.png"><img src="../images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png" alt="amir houieh - Knowledge Recognition-image4.png" title="amir houieh - Knowledge Recognition-image4.png" srcSet="../images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png 320w, ../images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-640.png 640w, ../images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-1024.png 1024w"/></a></figure><figure class="horizontal"><a href="javascript:;" title="amir houieh - Knowledge Recognition-image5.png"><img src="../images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png" alt="amir houieh - Knowledge Recognition-image5.png" title="amir houieh - Knowledge Recognition-image5.png" srcSet="../images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png 320w, ../images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-640.png 640w, ../images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-1024.png 1024w"/></a></figure></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"project":{"html":"\u003cp\u003eKR was our first big experiment at \u003ca href=\"https://suslib.com\"\u003eSuslib\u003c/a\u003e. The idea was simple: what if a collection of books, images, or files could actually understand itself? Instead of being a flat archive, it would be a network of meaning that you could search semantically and explore contextually.\u003c/p\u003e\n\u003cp\u003eThis was 2018, so we didn\u0026#39;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word2Vec embeddings and dropped them into Elasticsearch to give collections a \u0026quot;search by idea\u0026quot; capability. It felt like hacking the future together with duct tape and GPUs.\u003c/p\u003e\n\u003cp\u003eI led the team that built it — backend, ML, and MLOps engineers — and my role was to drive the product architecture, glue all the moving parts, and also get my hands dirty with model training and pipeline design. We wrapped it all into a REST and streaming API that sat neatly between a CMS and database. That made it lightweight, flexible, and fast enough to power our own AR inventory app while still being useful for outside developers.\u003c/p\u003e\n\u003cp\u003eLooking back, KR was the project that put us on the map: it got us into Dutch Design Week, helped us secure funding, and proved that we could build practical AI-driven knowledge systems before the ecosystem was ready for it.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ewith\u003c/code\u003e \u003ca href=\"https://suslib.com\"\u003eMartijn de Heer\u003c/a\u003e, \u003ca href=\"https://suslib.com\"\u003eHomayoun Moradi\u003c/a\u003e\u003c/p\u003e\n","link":"https://suslib.com/core/knowledge-recognition","title":"Knowledge Recognition","description":"\u003cp\u003eThis was 2018, so we didn\u0026#39;t have transformer models or ready-made semantic search APIs. Instead, we pieced it together ourselves: YOLOv3 and Mask R-CNN for object detection, Tesseract for OCR, spaCy for entity recognition, LDA for topics, and TextRank for summarization. For semantics we trained Word2Vec embeddings and dropped them into Elasticsearch to give collections a \u0026quot;search by idea\u0026quot; capability. It felt like hacking the future together with duct tape and GPUs.\u003c/p\u003e\n","blurb":"AI-powered semantic search system that transforms collections into networks of meaning using computer vision and NLP.","tags":["AI","semantic-search","ML","knowledge systems"],"slug":"knowledge-recognition","thumb":{"src":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png","srcSet":[{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-320.png","size":320},{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-640.png","size":640},{"path":"images/amir_houieh-C0YVQVhOFqm6SHcj0UqFT-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-knowledge-recognition.png","order":-1,"r":1.5},"images":[{"src":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png","srcSet":[{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-320.png","size":320},{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-640.png","size":640},{"path":"images/amir_houieh-XSEIvrrJCBLgd8BP2KLLa-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image1.png","order":-1,"r":1.5},{"src":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png","srcSet":[{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-320.png","size":320},{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-640.png","size":640},{"path":"images/amir_houieh-1TaLtYIGZIkPQiXr0GwxE-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image2.png","order":-1,"r":1.5},{"src":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png","srcSet":[{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-320.png","size":320},{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-640.png","size":640},{"path":"images/amir_houieh-AqAIHCEqcvrerxPmEkUv1-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image3.png","order":-1,"r":1.5},{"src":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png","srcSet":[{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-320.png","size":320},{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-640.png","size":640},{"path":"images/amir_houieh-lvxhqPFVHuZ39k70lsZE8-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image4.png","order":-1,"r":1.5},{"src":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png","srcSet":[{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-320.png","size":320},{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-640.png","size":640},{"path":"images/amir_houieh-T79_Z0sEb5XqEMwybaIQ4-1024.png","size":1024}],"caption":null,"alt":"Knowledge Recognition-image5.png","order":-1,"r":1.5}],"stack":["YOLOv3","Mask R-CNN","Tesseract OCR","spaCy","LDA","Word2Vec","Elasticsearch","TensorFlow","PyTorch","REST API","Streaming API"],"dateString":"2018","dataYear":2018,"videos":[]}},"__N_SSG":true},"page":"/[slug]","query":{"slug":"knowledge-recognition"},"buildId":"aqAUvMRKsTzW4luGvoG2f","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>