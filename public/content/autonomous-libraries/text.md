---
title: Autonomous Libraries
year: [2020]
tags: ["R&D", "future-of-knowledge", "smart-city", "IoT"]
stack: ["Word2Vec", "Elasticsearch", "OCR", "CV", "NLP", "OpenPose", "YOLOv3", "LSTMs", "TensorFlow", "AR interfaces", "modular architecture", "HCI"]
link: https://suslib.com/research/autonomous-libraries
---

Autonomous Libraries (AL) was an R&D project where we asked: what would a library look like if we designed it from scratch for the age of digital knowledge production? Instead of one big central building, AL imagined a distributed network of hybrid knowledge spaces — modular, self-managed, community-run, and spread across everyday environments like coffeehouses, squares, or train stations.

We combined all the core technologies we had developed at Suslib — Knowledge Recognition for semantic search and contextual linking, Intention Recognition for gesture- and object-based interaction, and lightweight AR interfaces to connect digital and physical resources. The result was a new kind of space: one where you could pick up a book and instantly see its digital context, annotate a page with thoughts and images, or continue reading seamlessly on your device after leaving.

As a team, we treated AL as both a design research exercise and a technological prototype. I led the engineering direction, ensuring our APIs and ML systems could integrate into a hybrid physical-digital environment, while collaborating closely with Martijn on interaction design and Studio Helioripple on modular architectural systems.

AL was never meant to be a single app or product, but a vision of community-driven, resilient, non-commercial knowledge infrastructure — one that could exist anywhere in the city, belong to everyone, and evolve with new forms of knowledge production.

`with` [Martijn de Heer](https://suslib.com) (co-founder, designer), [Studio Helioripple](https://suslib.com) (Amin Bahrami)
